[
  {
    "title": "The state of play of data center development",
    "description": "The future of the grid increasingly hinges on where and how data centers get built. To forecast the kind of power infrastructure we need to meet AI\u2019s growing appetite, we first need to understand a laundry list of variables: data center size, workload type, latency, reliability \u2014 even the variety of a data center\u2019s coolant system.\u00a0\n\nSo what\u2019s the state of play in data center development today \u2014 and how are the trends shaping grid needs?\n\nIn this episode, Shayle talks to Chris Sharp, chief technology officer of Digital Realty, a developer, owner and operator of data centers. They cover topics like:\n\nHow AI inference workloads are clustering in existing regions, driven by latency and throughput requirements\n\n\u201cData gravity\u201d and \u201cdata oceans\u201d: how large concentrations of data attract more compute infrastructure\n\nWhat\u2019s driving longer lead times: interconnection delays, equipment bottlenecks, or both?\n\nLarge-scale builds vs. incremental additions and densification of existing infrastructure\n\n\u201cBraggawatts\u201d vs. real demand: separating hype from reality\n\nThe diverging power needs of training vs. inference, and whether any workloads work with intermittent power\n\nThe evolving role of \u201cbridge power\u201d and why diesel and gas are still in the mix\n\nResources:\n\nLatitude Media: Google\u2019s new data center model signals a massive market shift\n\nLatitude Media: The future of energy-first data centers takes shape\n\nLatitude Media: Can a new coalition turn data centers into grid assets?\n\nLatitude Media: Do microgrids make sense for data centers?\u00a0\n\nThe New York Times: Wall St. Is All In on A.I. Data Centers. But Are They the Next Bubble?\n\nCatalyst: The case for colocating data centers and generation\n\nCredits: Hosted by Shayle Kann. Produced and edited by Daniel Woldorff. Original music and engineering by Sean Marquand. Stephen Lacey is executive editor.\n\nCatalyst is brought to you by Anza, a platform enabling solar and storage developers and buyers to save time, reduce risk, and increase profits in their equipment selection process. Anza gives clients access to pricing, technical, and risk data plus tools that they\u2019ve never had access to before. Learn more at go.anzarenewables.com/latitude.\n\nCatalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. See how EnergyHub helps unlock the power of flexibility at scale, and deliver more value through cross-DER dispatch with their leading Edge DERMS platform, by visiting energyhub.com.",
    "summary": "The podcast discusses the evolution of data centers in the context of the energy transition, focusing on the development and operation of co-located data centers globally. The guest, Chris Sharp, CTO of Digital Realty, shares insights on the geographic dispersion of data center growth, the impact of AI workloads on infrastructure requirements, and challenges around power availability and infrastructure development timelines. The conversation delves into the increasing demand for larger data centers, the nuances of workload requirements, and the balance between scalability and operational efficiency in the data center industry. Sharpening focus on power availability, infrastructure constraints, and the evolving landscape of data center development and operation.",
    "transcript": " Latitude media covering the new frontiers of the energy transition. I'm Shell Kahn, and this is Catalyst. There's a lot of noise, like one of the things we've been joking about is a lot of braggle-wats. Oh, I have a gigawatt. I have a gigawatt. Coming up, what's more insatiable, power demand from data centers or my appetite to talk about it? I'm Shell Kahn. I invest in early-stage companies and energy impact partners. Welcome. So we've, of course, spent a lot of time on this podcast talking about the Energy Data Center Nexus. Too much time? Who's to say? Objectively, it's the biggest thing happening right now, so buzz off haters. Anyway, one thing we haven't done amidst all that discussion is talking to somebody who's actually building data centers, and has been for a long time, for that matter. So that seems dumb. Fortunately, there's Chris Sharp. Chris is the CTO of Digital Realty, which has been around for 20 years, developing, owning, and operating co-located data centers all over the world. Chris is just very insightful about what's going on in the space and what's coming next. So I brought him on to talk about what the hell's happening in data center world, and a fair bit about what's happening at the data center power nexus. Here's Chris. Chris, welcome. Thank you. Thanks for having me. Looking forward to it. Excited to talk about the state of data centers in the world. I think particularly in the United States, let's restrain ourselves to something reasonable to talk about, because there's a lot to talk about even here. You've been in data center world. How long now? Like 15 years or more? Yeah, 15 plus years. Longer than I could admit, believe me, when I started, it wasn't cool, and it wasn't at the forefront of every headline. So that's changing. Congrats on finally being cool. Thank you. I wouldn't go that far, but okay. Yeah, sure. I want to start by talking about geography a little bit. Again, maybe we'll focus primarily on the US. I mean, my perception of how this world has evolved is that historically, the data center development activity and operation activity was very concentrated in a pretty small number of regions, Northern Virginia being the one everybody probably knows the most about, but then there were like some other tier two regions behind that. And that part of what has happened in this new wave of excitement and AI and hyperscale data center is getting planned everywhere, is that there's been a big geographic dispersion. And so I guess one question for you is, is that true or is it still really regions that drive the majority of the growth? Yeah, so I think you have to take a step back and look at the problem from two lenses, right? The first lenses is, what are the workloads coming to market? And I think that lens is interesting, right, where the most simplistic terminology people hear about training and inference, I think training has forced a broader regional deployment, but that's for training these kind of frontier models. I would say that there's been a lot of growth in that, but we see that kind of leveling out, where we really see the consumption of AI are inference, that's driving that regional specific growth going forward. And I think that's where it's more embedded in a lot of the existing, if you will, follow the clouds with availability zones. That's where it's really starting to be that investment growing and evolving quite quickly. And I think you brought it up with Northern Virginia that NOVA market has been one of the critical availability zones, which is now represented as a critical kind of AI growth sector going forward as well. When you say availability zone, what's the promise? What's the availability promise that's being made? Because this is what's driving its regions for this reason, right? 100%. It is a promise of a certain level of availability. Yeah. And so I think I always do a one step further on that training inference, but it's monetization. Those availability zones were foundational and set up gravity, if you will, of what was driving that as SLAs and consumption to the enterprise, right? And I think that's where you see a lot of these capability and infrastructure being invested in these zones all around the globe, where there's a major city center. It's usually closer to the CBD because there's proximate requirements with throughput and latency associated with it. But those availability zones are what has built that kind of, if you will, first wave of cloud infrastructure coming to market. And availability zones are slowly evolved. They're not everywhere. They're not in these tier two, tier three markets, but we're seeing a lot of AI applications being embedded inside of those availability zones. And the last piece I believe you with is that AI is an and not an or to cloud, right? I want people to really comfortable with that is that a lot of these AI capabilities are being embedded in the cloud services you're consuming today, like co-pilot and some of the early capabilities come into market. But that's how we really see a lot of these markets maturing over time. You mentioned latency there. So my laypersons understanding here of what you were describing is, okay, training a model, you can kind of do anywhere, but the models are getting bigger and bigger and bigger. And so we need bigger and bigger data centers, but they're not as geographically constrained. And thus, you can put a training focused data center, maybe in the middle of nowhere, assuming you have all the other things that you need, you have power, you have labor, you have water, et cetera, et cetera. But then inference latency matters more. And thus, you want high and not only latency, but I guess availability as well, because these are time sensitive requests. And so that's why you want to be clustered in a region and so on. I've heard some people, this will get to the energy data center nexus a little bit, speculating that you could bifurcate even the inference workloads into things that are latency sensitive and things that are not. And the ones that are not, maybe you go take advantage of cheap, clean power, maybe even intermittent power out in the middle of nowhere, which definitely exists, but is not where the rest of the data centers are getting cited. Do you view that as a viable approach, given the actual workloads? It is, it is. And it's great that we're going through the workloads, right? Like that workload is what depicts the infrastructure required to making it successful. And I think latency and throughput remain many different things. And so I always try to double click on a little bit. The amount of throughput required is what's challenging, right? And latency, as long as it's consistent for a lot of the workloads we see, they can operate fine. But it's that throughput, the amount of data that's required for delivering kind of an inference type of solution is something that is again proximate, not only to the consumer, but proximate to an ecosystem. So I'll, I'll, I'll hit on your second point where, yeah, we see a lot of text to text scenarios where that workload can be deployed, you know, in two or three markets throughout North America and service the entire market. And so that's a very simplistic kind of scenario where we're in the early innings of AI and the complexities hasn't, hasn't really come to fruition for the broader market. But as you see, bimodal, some of these more advanced reasoning models where a token isn't just generated against a prompt and then you consume it and it's done, a token may be generated inside of an AI world and go through multiple models to ensure that, you know, it's not hallucinating or that it has a mixture of experts or a depth expertise in that outcome of that token. So that's where these ecosystems of other AI infrastructure being proximate to itself, not only just the data, but I would be remiss not to hit that AI is only as smart as the data sets you feed it. And so those training, you were able to feed that monolithic set of data in the middle of nowhere, but now we're more real time micro learning inference. It's starting to become more proximate to where the data oceans and that data gravity, which we've produced a report a long time ago is happening around these availability zones and these epicenters of these tier one markets. So it sounds like what you're saying, if I'm interpreting it right, is that this notion of let's go where this just all else equals go where the stranded power is. It probably has some validity because there are some workloads, text to text, for example, as you said, that can handle that where the throughput requirements are not so high and the latency requirements are not so high. But it also sounds like you're saying the direction of travel is in the opposite direction because actually the workloads are becoming more sophisticated, leveraging multiple models and the throughput requirements are getting higher. And so that set of opportunities, just go wherever the cheap available power is probably dries up, or at least the relative share of like how much you can build in that use case versus how much you could build if you actually have a cluster. And it's all regional and it's near all the other models. Like that's going to be a much bigger opportunity. Do I have that about right? Yeah, I know you're spot on. And there's a confluence of events that are happening there. It's not just power. The expense to stand this infrastructure up is these chips are not cheap, right? And so being able to utilize that over a longer horizon of workload and driving that utilization is also a form factor of if I haven't installed for training and training can be very a spiky workload that I can embed. And that capability get higher utilization out of that investment because the Royce is real on this. And so you see a lot driving that direction as well. But no, as we see these higher value kind of aggregators, if you will, of multiple models, right? Multiple capabilities. That's really starting to become more proximate to one another. And again, data is everything to a lot of these environments, be it hyperscalers or be it enterprise, which we focus on both having the ability to embed algorithms or this accelerated compute infrastructure in close proximity to their existing data oceans or constant data creation models is everything to our customers. Okay, so assuming that the majority of the growth will continue to occur in regions, maybe not all in today's tier one region, but that it's still going to be sort of a regionally driven market. I guess the question is how quickly do we tap out these regions from a power perspective in particular, because unless you tell me otherwise, I think that tends to be the thing that maxes out first, unless you tell me maybe it's labor, but like, let's take, we talked about nova, right? And then you, how close to tapped out are we there? How much more can we possibly build in that region? Yeah, so you bring up great points, right? Where tapping out is the right word where in a lot of these markets power has been tapped out. I mean, it is a phenomenal market. I mean, some of the most recent stats, it has 0.5% vacancy rate, which is phenomenal. I mean, it's a multi gigawatt market. I think, you know, one of the things that differentiates how we view these markets is coming in and master planning, not only with like the entire market, but the market. And not only with like the entitlements and making sure you have access and the rights to the land, but that master planning arc is sometimes five plus years in a critical element that is working with a utility operator so that they know that, you know, when we say we're going to need a gigawatt, like with what we're building right now right next to the Dulles airport, that they have an understanding of that power requirement. And in a lot of the cases, they're able to meet that, but in certain cases, particularly in Northern Virginia, which has been wildly, you know, publicized is the, you know, some of the not necessarily generation, but the distribution of the grid has been challenged. And so we're always working with different solutions to overcome those shortcomings in the short term, but then ultimately working with that utility operator so that they get an understanding of the future growth associated with these markets because, again, this infrastructure and by saying this, this AI kind of secondary wave to cloud wants to be proximate to existing infrastructure. So being able to tie those things together and the power has been challenging, right? And I think it's challenging not only throughout the globe, but in a lot of these markets where you need to be working with the utility operators, which is why I love talking to the market and educating not only the in consumer around what's happening in AI and the workload, but ultimately the broader infrastructure like the utility operators and some of the other technology coming to market and solving for that power constraint. Yeah, you mentioned timelines. I wanted to ask you about that. So it's obviously location specific, but can you talk to me particularly relative to your history in this sector from, I don't know, from the beginning of development of a new site to operations of that site? What does that timeline look like? What's the range of timelines that that looks like today? And how does that compare to history? Yeah, so it is a challenging scenario where all things being equal. It takes about two years from concept to delivery to build out what I would say, versatile data center. And by versatility, I mean, comprehensive portfolio of solving for the hyperscaler needs, but also solving for the enterprise customers. So that's a 24 month window, but with the backdrop that we're experiencing, particularly with the power and the grid and just the overall equipment bottlenecks, I mean, utilities are requesting aggressive kind of four year rent projection that when you start to take that power down, you need to utilize it, which we've been very good stewards in a lot of these markets that when we do that master planning, we project that we are going to need 500 megawatts. We take down that 500 megawatts and operate that over a longer period of time. But some of these other, you know, interconnects are definitely no two markets are alike, but they're elongating even beyond the 24 months that it would take us to pull that together. So there's a lot of challenges there. And I referenced that at a high level, but some of the, you know, broader infrastructure constraints are transformer lead times are 50 plus weeks right now. Well, I was going to ask you about that. Right. Cause, cause transformer lead times and switch gear and stuff like that, that, that has been a challenge in all sorts of areas of the power sector. But I wonder whether because you have the added constraint of really long interconnection lead times, does it just mean that the interconnection is the long poll and the tent? And so you sort of, you have enough time that the transformer thing doesn't actually, or switch gear, whatever, doesn't actually delay projects because you happen to have another thing that takes even longer, or is it its own constraint? Yeah, there's, there's two high levels. It is a constraint. Don't get me wrong. There's two high level elements that we've been doing at digital for. I've been here 10 years, companies around 20 years is vendor managed inventory. So not only understanding, Hey, here's our portfolio in a single market, but really operating at a point where we're buying that switch gear, buying that infrastructure ahead of time where we can alleviate some of the bottlenecks. But yeah, that secondary constraint. And this is why I referenced earlier the master planning, showing and signaling to the utility operators and being a good steward of having top tier customers and credit worthy customers in our portfolio, which want to operate with us 10 plus years in that asset, balancing that together is everything. And so that interconnect from the utility has become constrained and some markets were always investigating different types of solutions, gas turbines. And even those are backlog plus 2029, right? Like that's, that's an extensive background as well. Yeah, we're definitely going to talk about bridge power because that is super interesting. Before we do though, one of the question I have for you about sort of how the market has developed is about scale of data centers. And we sort of alluded to this when we talked about, okay, that the training models need really big scale data centers. But you know, over history, right? Like you guys probably were developing 20 megawatt data centers 10 years ago, right? And now it's hundreds of megawatts. Or you mentioned a gigawatt. What does the demand picture look like for you? Does everybody want the biggest possible data center that you can build them? Or like, what is the nuance to that? Yeah, it's a good piece to dig into, right? Where there's a lot of noise. Like one of the things we've been joking about is a lot of bragawatts. Oh, I have a gigawatt. I have a gigawatt. And there's just so much noise out there that you really want to get underneath the workload and the durability of the company behind the workload. And that's where, you know, being a publicly traded operator, we're constantly watching that. And not everybody needs a hundred megawatt data hall. And there's certain use cases where a contiguous set of GPU infrastructure, which requires a very discreet capability, which we have some of the strongest heritage of engineering talent within digital. That have been solving this for the clouds. And now it has grown, but they want a contiguous hundred megawatt GPU array. So it's not just about the total capacity block, but then it's the densification of that capacity within the asset. And so we're always watching that. But what we're really seeing is inference can come in in like five ish megawatt blocks. And you can solve for it a bit differently. Now the densification is still there. And then the private AI pieces, there's hotspots where it can be, you know, a couple of months. But they want to be embedded in their existing portfolio of assets and balancing those two things as something we're always eyes wide open. But so this gets to an interesting question I've been wondering about, right, which is mostly what you hear about these days is right. You're hundred plus megawatt data centers getting built mostly hundreds of megawatts, if not gigawatts, right? And that that's what all the news is about. But if the individual inference workloads need to be, they can be five megawatt chunks, albeit you want some degree of densification, could you employ a strategy where you go build a hundred twenty megawatt data centers all in a region? Is that a viable approach? Because from a power perspective, my suspicion is that in the regions with a lot of data center activity already, it might soon, the scales might soon tip where it could actually be easier to build a hundred twenty megawatt things than a single two gigawatt thing or a single two one gigawatt things. Yeah, one of the most challenging things represented by AI is the ambiguity in the workload, right? Like there may be one workload that are like, yep, okay, I can take five or fifty one megawatts and I don't care where they are. That's less than, that's the outlier of what we're seeing is that to operationalize, they would really like it to be more of a contiguous scenario where they do logically think about them as five megawatt chunks and they want a bit of resiliency. You would, you would set it earlier. Reliability becomes increasingly important with inference because that's the consumption of that capability. What we're seeing is having a hundred megawatt hall where a bunch of five megawatt deployments could come in and be represented as inference. That has a higher viability for a lot of the hyperscalers plugging in, you know, a multitude of capabilities because it's not one AI workload. It could be a bit of, you know, I always challenged it not to reference a specific workload that I'm working on with a specific customer, but just some of the stuff spoke about publicly, but you look at like some of the most recent capabilities. I mean, when I was in an announcement from Google and like Gemini and the, and Vio three, those are probably compromised, like, like coming to market as a composition of multiple, you know, inference capabilities coming to market to meet that customer demand and you have to solve for the peak, right? Like people always forget like we learn this in the web scale, hyperscale. It's like the grid. It's the exact situation is the grid. Right. Exactly. We build the grid for the peak. We also build data centers. You have to. Absolutely. You mentioned the Braggle lot thing. I mean, that's the other thing that feels to me like we're clearly in a moment. Like two things can be true at the same time. There can be explosive actual demand growth for compute leading to actual need for lots of gigawatts of new data centers. And also it can be true that the volume of data centers quote in development and certainly the volume of load interconnection requests going to utilities is like an order of a low-income data center. Is like an order of magnitude more than is actually going to happen. Like both of those things can be true. But I wonder the degree to which that presents a challenge for folks like you because you're, you know, you need to get stuff built. But on the other side of the table from you is utility who's inundated with load interconnection requests and needs to figure out which things are real and which things are not. And I imagine that sort of gums up the works a little bit. Yeah. No, you're spot on, right? And I view that as three elements, right? Where, you know, the power, the amount of power and even the amount of financing required to meet these upper end projections, it doesn't exist. Right. And so you can't solve it all even if you wanted to. But then double clicking on aligning to your customer, right? And not all customers are equal and really understanding what their goals are and what they're trying to achieve. That's the heritage of digital reality, right? And that's where we've been doing that in pretty much every theater on Earth over multiple cycles, right? So AI represents a new cycle in a new way that's bigger and faster than we've ever seen before. But it takes partnerships to really pull that off correctly. And I think, you know, I couldn't say it better in that, you know, some of the works that we've been doing together collectively and also with utility operators having a communication with them to show that, you know, we, they won't over the course of the world. We, they won't overbuild unless they have a level of comfort that you will take and utilize that infrastructure they brought to market. So that ramp is everything to them. Working with that customer to show them that we have the right customers, we have the understanding to support the workload is everything because there's going to be some probably written about very big challenges and failures where they wanted a total capacity block, but they couldn't support the densification or they were just building for the spike. It was very spiky, but the longer term utilization is much lower than anybody had projected that will have very negative impacts on them to operate in a longer term horizon. So we're always focused on right types of customers, right types of partnerships to meet that peak load demand and the finance is required to hit it. Okay. So you mentioned bridge power. I want to, I want to hear how that is playing out in the market. We hear a little bit about it, right? There are folks who are saying, I mean, the famously the grock data center employed this substantially where you just say like, okay, the grid interconnection timeline is too long. And so I'm going to throw a bunch of generators on site and operate off of the generators as a bridge until the grid comes along for me. How common is that actually? Yeah, I think there's some outliers. Very few of it gets covered in the press because nobody wants to really go on to the market where the grid can't meet the customer ramp demands today. I mean, full stop. And I think, you know, one of the things that we're always looking at and I keep harping on this is that customer ramp requirements are an absolute key driver, but bridge power is one tool among many that we're always looking at, right? And, you know, natural gas, which is what you were referencing earlier. I think it has a solution in a shorter term horizon, but we're always looking at what are the longer term power generation capabilities that could potentially coming online and working with the utility operators on if it is grid constrained and they couldn't get the resiliency in the grid. Or if it's a generation challenge, we're always looking at how do you hit that peak demand with some of the batteries and some of the other technology that we've been seeing come to market. But yeah, it is an outlier. I think a lot of the utility operators are starting to understand that, hey, this is real demand and all aligned to it. They're not chasing the noise because nobody wants to invest in a bubble, right? Like I'll go on the record to saying that we're always looking at to ensure that we're not aligned to a bubble and that long term durable workload is there. But yeah, we too investigate net gas turbines. We investigate all options within the grid to overcome some of the shortcomings so that we can service our customers because I think it's often missed. You know, I talked to the utility operators that if our data center, you know, goes dark and is dormant, it doesn't allow our customers to grow and hit that next capability they need represented as AI or not or even cloud services. They have to be able to get revenue out of that very expensive infrastructure going forward. So they're looking for that long term master planned alignment to the utility operators. My sense is that there's kind of two different things you can do. If you think about bringing assets beyond the assets you would normally bring, right? You're always going to have backup power or whatever. But if you're going to think about bringing anything beyond that alongside behind the meter at a data center, you can either do the pure bridge power thing, which is we will supply. Our own generation and operate the data center off grid or partially off grid until the interconnection arrives or there's this other thing, which is, okay, we will proactively strike a deal with the utility, wherein we will bring our own generation or we'll bring our own batteries or whatever it might be and we'll have an interruptible tariff or something like that. And in so doing, we will get faster time to power, but it's a negotiated deal with the utility as opposed to a bridged utility. My sense is that the latter version is more common, more prevalent than the former. Is that right? Absolutely. Yeah, absolutely. And it's because we don't want to be all things to everyone because we won't be good at anything, right? Where you want to invest in the utility to allow them to do what they were good at and get over this challenge of the spike in demand, but that longer term environment should be with the utilities. And that's why we form long term relationships with the utility operator and act as a good customer to them on behalf of our customers. It's that chain of value that we're always watching because doing behind the meter, becoming a power generation capability, I think, is a short term gap. Nobody would be investigating that if we didn't have the constraint. And so that in itself tells you that a lot of individuals want to stay to their core stitching of, hey, what are we good at? What is our core capabilities we're bringing to market? But I think there's a short term. Let's meet the demand and the longer term who would be better at managing and operating these things going forward. The way I think about the archetype of what are the energy resources added to the center historically was you would have a UPS system and you would have backup power. And those are basically you had a diesel generator and EPS system and that like every day the center had those things. Do you think that'll change? Is there a new archetype? I was hopeful early on, but I've never seen one built with the right type of SLA. So set a bit differently. Yeah, I want a straight in facility where the software would have resiliency to fail over, where I didn't have to invest in all the diesel generators or some backup system if the utility failed. I haven't seen one come to market, but we've always been watching that because there is a lot of, I mean, believe me, I don't like to admit the secondary piece, which maybe a lot of the listeners already recognize. We operate almost three gigawatt diesel generators today. And so finding that balance and we do utilize some of those for peak loads and peak shaving and things like that. So we'd love to build an environment where for certain workloads we can build a different type of data center, but just because of the SLAs because of the requirements associated with these chips where they're liquid cooled, right? And that liquid cooling, you want almost three in worth of reliability where if that pump goes down that those hot set of infrastructure that accelerated compute continually has the right type of liquid for a certain period of time where it doesn't damage that infrastructure and we're talking about billions and billions of dollars for 30, 35 megawatt build up to 50 megawatts, it's very expensive infrastructure that we're watching. So high hopes, but it never really came to fruition. That's a really interesting point, one that I hadn't fully appreciated, that liquid cooled actually possibly increases the need for reliability, if anything. That thermal doesn't go away. Even if you had a workload that didn't need it, right? Because the promise, the thing that people talk about sometimes, it feels like it's this like ethereal concept. That never occurs really is like, oh, but there are some workloads that don't need three nines of reliability or five nines of reliability. It's like, okay, right? We're tagging, the cloud example used to be like, we're tagging photos for Google images or whatever. You should be able to operate those in a different manner. You shouldn't need the diesel generator. You should be able to place it wherever you want it. We should relieve all these constraints. I think there was this concept that, look, if the grid is as big a bottleneck as we think it will be, and it gets just harder and harder to find sites to build data centers at the scale that we need, then naturally, the market is going to start to separate out those workloads and put them in the places that you can still build. But there are all these other constraints. It's not just about the workload. It's, though that is challenging for the reasons you said before, it's also like you don't want to fry the chips, basically, and you've invested a lot of CapEx in those chips. Yeah, and you can double click on the infrastructure. There's probably some components that could go in and have a little bit more resiliency. But if you're liquid cooled, the thermal doesn't just displace itself. So you have to continually run liquid through that so you don't damage the chips. But to your other point, the availability zones have grown, right? Because of the constraint, lack of land, lack of entitlements, they've grown, but they're still proximate to that kind of CBD within these critical markets that we see evolving quite in the foreseeable future. We just see so much demand with as more customers start to utilize AI and the complexity of these models come to market, you only see that increasing. All right, final question for you, Chris. What are you most excited about? Like, what's the coolest thing that might be coming on the horizon in data center technology world? Yeah, so I think some of the newer designs we see and some of the efficiency factors. What's awesome is, you know, having two small children myself, we want to be good stewards of the power we take from the grid. So the P we ease increasing, shifting to liquid, you know, liquids 800 times denser than air, so you can get more efficiency factors out of that. I think that's going to be a net positive. And then, you know, I'm a technologist at heart. Some of the designs of the hardware coming to market are just phenomenal, right? And working with our partners that, you know, across the broad spectrum, watching and working within video, Vladimir Troy, who runs R&D there, we spend a lot of time with him, not just on the current generation that the public gets to see, but what are the two and three generations out? The ability of the token production against the Watts associated with that is going to be phenomenal. And hopefully everybody, all of our listeners here today, they understand the value of not only the data center, but these tokens and AI. I'm a very pro AI kind of individual. There's some, there's always going to be some negative associated with it, but what AI is going to be able to do for us, not only as individuals, but as a society. I mean, I'm pretty excited about some of the use cases and workloads that we've seen. One case I would leave you with is Gefian, a project we did out in Copenhagen. It's one of the largest DGX pods for Novo Nordisk. Just the amount of pharmaceutical work associated with that one deployment is just what it's going to be able to do for me. And it is very exciting to me. All right, Chris, this is a really fun conversation. Appreciate the time as always. I appreciate it. Thanks for the opportunity. Stay safe out there. Chris Sharp is the CTO of digital reality. This show is a production of Latitude Media. You can head over to latitudemedia.com for links to today's topics. Latitude is supported by Prelude Ventures. Prelude backs visionaries accelerating climate innovation that will reshape the global economy for the betterment of people and planet. Learn more at PreludeVentures.com. This episode was produced by Daniel Waldorf. Mixing and theme song by Sean Markwand. Steven Lacey is our executive editor. I'm Shale Khan, and this is Catalyst.",
    "release_date": "2025-06-12",
    "duration_ms": 1974000,
    "url": "https://chrt.fm/track/G78F99/traffic.megaphone.fm/PSMI5249436938.mp3?updated=1749695228",
    "source": "Catalyst with Shayle Kann",
    "timestamp": "2025-06-15T01:57:01.361249"
  },
  {
    "title": "The gas turbine crunch",
    "description": "Demand for turbines is growing fast, but so are lead times \u2014 causing serious headaches for developers. In Texas, one of six projects that pulled proposals from consideration for a valuable financing program cited \u201cequipment procurement constraints\u201d as the reasons for its withdrawal.\n\nLead times are stretching to four years and sometimes more. Costs are climbing. So what\u2019s behind the bottleneck?\n\nIn this episode, Shayle talks to Anthony Brough, founder and CEO of Dora Partners, a consulting firm focused on the turbine market. Shayle and Anthony cover topics like:\u00a0\n\n\n  \nWhy previous boom-bust cycles in turbine manufacturing have left the industry skittish \u2014 and why Anthony says leaders are approaching this new peak with \u201cguarded optimism\u201d\n\n\n\n  \nThe competing demands on the turbine supply chain, including from power, oil and gas, and aerospace industries\n\n\n\n  \nHow lead times have ballooned to four years and, in some cases, even longer\n\n\n\n  \nFactors affecting the market beyond load growth, like renewables, storage, affordable gas, and coal retirements\n\n\n\n  \nHow investment in tech innovation has raised turbine efficiency\u00a0\n\n\n\n  \nHow the industry is preparing for hydrogen \u2014 if hydrogen scales up\n\n\n\n\nResources:\n\nLatitude Media: Engie\u2019s pulled project highlights the worsening economics of gas\n\nLatitude Media: High costs, delays prompt withdrawal of five more Texas gas plants\n\nPower Magazine: Gas Power's Boom Sparks a Turbine Supply Crunch\n\nMarketplace: Will we have enough natural gas turbines to power AI data centers?\n\nCTVC: \ud83c\udf0e Gas turbine gridlock #236\n\n\n\nCredits: Hosted by Shayle Kann. Produced and edited by Daniel Woldorff. Original music and engineering by Sean Marquand. Stephen Lacey is executive editor.\n\nCatalyst is brought to you by Anza, a platform enabling solar and storage developers and buyers to save time, reduce risk, and increase profits in their equipment selection process. Anza gives clients access to pricing, technical, and risk data plus tools that they\u2019ve never had access to before. Learn more at go.anzarenewables.com/latitude.\n\nCatalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. See how EnergyHub helps unlock the power of flexibility at scale, and deliver more value through cross-DER dispatch with their leading Edge DERMS platform, by visiting energyhub.com.",
    "summary": "The podcast discusses the evolving gas turbine market, focusing on key players like Mitsubishi, Siemens, and GE Vrenova. The industry has experienced boom and bust cycles, with factors like Enron's artificial demand in the past influencing market dynamics. Today, OEMs are working to shorten lead times amidst increasing demand and rising prices due to factors such as raw material costs. The market outlook shows guarded optimism with OEMs investing in future production capabilities. Different market drivers impact gas turbine sizes, from small to jumbo units, catering to various sectors like grid-scale battery storage, data centers, and renewable energy expansion. Lead times currently average around 36 to 48 months.",
    "transcript": " Latitude media covering the new frontiers of the energy transition. I'm Shail Khan and this is Catalyst. What's your outlook on timelines? Do you think that the lead times just get longer and longer and longer? Are we at the peak there? Is it going to get worse? Do we know? Good question. I actually don't think they're going to get much worse. I think all of the OEMs are working like crazy to try and shorten up their lead times or at least make sure they don't get worse. Coming up, it's due time we talk about the gas turbine market. Do you want instant access to energy storage supplier pricing that's project specific? Or the ability to compare domestically made battery and PCS options across the market? ANSA now offers the industry's first battery energy storage data and analytics platform to make better development and procurement decisions. ANSA provides in-depth commercial, technical and risk data and analytics to help developers choose the best equipment for any project. Improve your returns and save months of evaluation time with ANSA. Learn more about ANSA's energy storage subscriptions at go.ansarunuables.com slash latitude or click the link in the show notes. Imagine a world where connected devices like EVs, home batteries and smart thermostats work together to support a more efficient and reliable power grid. Well, you don't have to imagine it anymore. This vision is a reality today thanks to Energy Hub. With Energy Hub's Edge Derm's platform, utilities can create virtual power plants through customer centric flexibility programs, making it easy to manage distributed energy resources and balance the grid. Unlock grid flexibility and reliability through cross-DER management with Energy Hub, the trusted Edge Derm's leader. Visit energyhub.com to learn more. I'm Shail Khan. I invest in early stage technologies at Energy Impact Partners. Welcome. So it's a good time to be in the gas turbine business between the relaxation of emissions constraints and the rapid load growth that we've discussed in numerable times on this podcast before. Perhaps the biggest winners are the companies like Mitsubishi, Siemens and GE Vrenova who make turbines. Of course, one result of that is that they're pretty well sold out and they have a lot of pricing power. So it's an interesting moment where momentum is clearly flowing toward natural gas power generation, but it's also actually pretty difficult to build any more of it, especially in the near term. Anyway, it's a really interesting market and one we haven't really talked about here. So let's fix that. Directify the situation. I brought on Tony Bruff. Tony is the president of Dora Partners, which is an Energy and Gas consultancy specializing in what's going on with the gas turbine industry. Here's Tony. Tony, welcome. Thank you. Glad to be here. Start by you giving me a little bit of a recent history lesson on the gas turbine market. How has it been developing over the past? I don't know. You tell me what the relevant timeframe is, but a couple of decades. That's a good question. There's been a lot of dynamic change over the last few decades. I mean, it used to be in the 70s and 80s, there were pretty much just two major OEMs, General Electric and even Westinghouse at the time, now owned by Siemens. But really, the number of OEMs have been, have gravitated towards three major OEMs, MHI and Mitsubishi Heavy Industries, Siemens and General Electric or now it's GE, Vernova. There are other strong players in the market. For example, Solar Gas Turbins, a division of Caterpillar is a significant player in the small gas turbine market. So how has it changed? It's really evolved not just in terms of the OEMs, but also there's been several column bubble periods. There was a big bubble period in 1998, 1999 through 2001 and then the market basically fell off a cliff and it slowly built back up to a really good set of years back in 2012 and then it kind of fell off again. Now we're kind of at another peak, but I would call today's peak more of a real market-driven, realistic set of scenarios that's driving the market today. That's interesting that you say that. I knew it was characterized historically by these sort of boom and bust cycles and I think we've seen this in other sectors in the electricity market as well. We've talked before on this podcast about Transformers, for example, where you have these very long lead times and one of the reasons that there are still such long lead times as the transformer manufacturers have gotten burned in the past by building out more capacity and being oversupplied into a market that turned out to bust. I had a sense that there's a similar dynamic in the turbine world, but it sounds like you're saying this one seems like it's different. What drove those bubbles that then burst in recent history in the market? Was it over exuberance about new gas generation build that just didn't come to fruition or something else? No, actually, there's actually several different dynamics and that's a really good question. If you go back to that first big bubble back in 1998 through 2001, that was really being driven by an artificial demand created by Enron. I mean, they clearly were sending artificial signals to the marketplace that were driving up the cost of electricity significantly in several regions of the country, California, Texas and other areas. That was also right around the same time that deregulation was coming into play. Those two factors created a lot of panic in the marketplace. Keep in mind, the large utilities in the 60s and 70s, everything was regulated. They were pretty much just, they only built when they could get the public utility regulators to approve investment. As deregulation came into play, deregulation came into play, everybody was just basically learning, okay, how do we make money now that there's regulated, deregulated and semi-regulated markets to deal with across the country and even to a degree in areas outside the country in Europe and Asia, for example. And then the Enron thing just created a significant, I would say, artificial signal to the marketplace. So those two factors really drove a bubble in the market and a little bit of it was unreal. I would say at least half of the volume was artificial. Maybe to put a finer point on that then, because this ties to both the deregulation and Enron, which obviously are tied to each other, but is what was happening there a lot of speculative development of what would be merchant gas projects that never came to fruition? I want to draw that distinction because what's interesting about today's moment is that like, I don't know, I don't think there is a lot of new merchant gas being developed. Mostly what's happening is it's having utilities saying we need it for, because we need more capacity or it's data centers and they'll be the long-term offtake on the project. So you're actually not like subject to the merchant risk. You are subject to the will this data center ever get built risk, which is kind of a different thing. Well, that's true. But most of that activity was not merchant. Well, there were IPPs. There were a lot of IPPs and independent power producers that were speculating without a doubt. But there were a lot of orders that were canceled even by large, regulated and semi-regulated utilities like Southern Electric. They had a huge set of orders and a lot of that stuff had to get either canceled or bought and then resold on the marketplace. It was a real disaster for everybody when the bubble burst. So we'll get into the market today in a little bit more detail. But do you think that there is, given that history, given that there is some boom and busts and some cycles that the market has gone through, does that lead to a more conservative approach from, as you said, basically the three big OEMs that control what 70% of the market or something like that to expand capacity? Or do you think that they share the view that you expressed, which is actually this one's real. I'm not too worried about being overextended if I expand capacity. Now I'm sold out through whatever it is, 2029, 2030. And so I should just build as much as I possibly can. Like where do you think they are on the spectrum? Yeah. Well, I think there's guarded optimism, very guarded optimism. I mean, certainly all of the OEMs are investing in the future for new production capabilities, particularly Siemens and General Electric, or GE, or GE, or know why I should say. The other thing to keep in mind is about half of the gas turbines that's ordered in the marketplace aren't even for the electric power utility market. They're for the oil and gas market. And so all of the supply chain that's feeding those three OEMs and others are also competing for supply chain resources going into the oil and gas market. And some of those OEMs are also delivering into the oil and gas market. So there is a lot of interesting dynamics going on. And it's important to look beyond just the power generation or the utility sector when you think about what's happening in the marketplace. Yeah. Can you say more about that? I think that's one thing people don't always appreciate on the outside. What does that supply chain look like and what are the big categories of sort of end markets that these products gets sold into? Right. Well, that's a great question. I have basically, I described the supply chain for the gas turbine industry in four different levels. I call level zero is raw materials. So you know, you talked about transformers while copper is clearly a big raw material when it comes to transformers. But for gas turbines, it's the super alloys, nickel based alloys, chromium, all those other expensive key ingredients, titanium, all those things that are involved in the raw materials for gas turbines. That's what I call level zero. Level zero level one is actually manufacturing the raw pieces of product, for example, blades and veins and things of that nature that are being cast or forged. Level two is where they're actually manufacturing the gas turbine from all those components that were developed on level one. So that's where the OEMs are producing a, you know, what I call flange to flange gas turbine. And then level three, which is the fourth level, is where it all gets put together into a final package and delivered to an operator site, installed, commissioned after market activities, all that sort of thing. So all of those and then when you keep in mind, levels zero and level one are also being impacted by the aerospace industry. You know, there's something like 40,000 aircraft in backlog right now in the world. So guess what? All of the same level zero material suppliers and all the level one forgers and casting shops and things of that nature in what I call level one, they're all supporting the aerospace industry at the same time. So these, you can't look in isolation at the electric power utility market for gas turbines in isolation because you have to consider what's happening in the aerospace industry and what's happening in the power and the oil and gas industry. Because as I said, 50% of the industrial gas turbines that are delivered in any given year approximately aren't even for the electric power utility sector. They're for the oil and gas sector. And in terms of the market dynamics today, I guess, obviously we have this booming demand for gas turbines in the electric sector, whether on grid or off grid. Some people are doing gas turbines for bridge power, for data centers or whatever. But let's call that all in the electric sector ultimately. Agree. Is the demand, I mean oil and gas prices are low right now. Does that mean that there's low investment on that side? And so most of the demand is shifting to electric power generation or is that not sort of how the cycle works on the oil and gas side? Well, you know, that's a great question, Shala. The good news is for those that are involved in oil and gas industry is by and large, most of the large oil and gas players have long-term thinking in mind. So they're making five, seven and 10-year strategy developments for strategy. Now, well, in any one year, they might reduce their order activity because the oil and gas prices are down. Absolutely, that's correct. But in the long run, oil and gas companies basically stick to a strategy, that an investment strategy that keeps them investing. And typically what we see are what I call seven-year cycles in the oil and gas industry. It'll go up peak at about year seven and then come back down, slowly come back down and then go back up again and another seven-year cycle. And it's all driven by upstream activity for development of oil and gas, midstream for transmission and then downstream where you have a lot of LNG, refinery activity, all that sort of stuff. And all those things are somewhat independent of each other. So it does level out the market for the oil and gas industry a little bit, which means that the investment stays. And when you look at the midstream oil and gas market, most of the players midstream, they're making their money not on the price of oil and gas, but on transmission of oil and gas. So they're very much, I don't like to use the word immune, but the sensitivity to the price of oil and gas is really low. They're still going to make money because everybody's still using the oil and gas, albeit maybe at a lower price, but they're taxing fee for moving the oil and the gas through the pipelines is still pretty robust and they're making their money. So they're investing. Catalyst is brought to you by ANSA. ANSA offers a one-of-a-kind data and analytics platform and advisory services to support better project development and procurement decisions. For energy storage developers, ANSA's platform provides crucial information that you never had easy access to before. Now at your fingertips is real-time pricing for a long list of system configurations to suit any project. ANSA provides a 360-degree view of the market with lifecycle cost analytics and commercial technical and risk data. With ANSA, developers can easily determine which products to use in their designs, finance models, and RFPs. Learn more about how ANSA helps save time and maximize profit at go.ansarunuables.com slash latitude. Catalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. The EnergyHub platform takes the guesswork out of balancing energy supply and demand. It uses machine learning to control customer-owned distributed energy resources, like EVs, home batteries, and smart thermostats, to precisely shape load profiles for grid flexibility and reliability. As the industry leader, EnergyHub helps more than 80 utilities manage 1.6 million devices. That's more than any other edge derms on the market. Click the link in the show notes to learn more or go to energyhub.com. I want to talk about, I guess, two primary things with gas turbines in the market, particularly for electricity generation, where I spend a lot of time right now. One is timeline and the other is price. We hear a lot right now in the news about both of those things. On the timeline side, we hear about folks like Givernova being sold out through 2029 with an order book behind that that they can sell as much as they can build, at least at the moment it seems. Then, on price, I don't know visibility into the actual market pricing, but what an interesting data point that you might have seen recently was, I think it was John Ketchum, or somebody from Nextera said, a decade ago, I could have built a new natural gas project for $750 a kilowatt. I think I'm going to get the numbers close, but not exactly right. Today, it would cost me $2,500 a kilowatt. I don't know how much of that is the turbine itself, but I'm interested in the relationship between how long it takes to get new turbines and how expensive they are becoming. Yeah, good question. That $750 was for a combined cycle plant. I think the $2,500 is a bit aggressive, but it's definitely up around 30 to 35% over the last five years. The price is definitely up. I track all of that very closely. Is it purely a supply-demand thing? No. Yes and no. Again, raw materials at level zero, raw materials are up everywhere. Even before all of the tariffs come into place, you were seeing demand on aluminum, nickel-based alloys, titanium, all of these things are all interrelated. Again, I'm coming back to the aerospace industry. When you've got the aerospace industry ordering 40,000 aircraft, that's at least 80,000 gas turbines. They're all drinking from the same supply chain, for the most part. No, it's not just supply and demand. It's also being driven from, well, it's of course, supply and demand is related to the cost of raw material. I don't want to discount that. But certainly raw materials is a big part of it. If you look at some of the US government's tracking of producer price indices on all of these different elements, you'll see a pretty significant bump in the last three years that is very indicative of what you and I are just talking about. What's your outlook on timelines? Do you think that the lead times just get longer and longer and for a while? Where are we in the cycle of the lead times having been getting longer? Are we at the peak there? Is it going to turn back the other direction? Is it going to get worse? Do we know? The good question, I actually don't think they're going to get much worse. I think all of the OEMs are, in fact, I know all the OEMs are working like crazy to try and shorten up their lead times or at least make sure they don't get worse. Part of the reason why is customers are eventually just going to get weary. Say, OK, we're just going to put things off because as it is, they're putting down 15, 20, 25 percent non-refundable deposits. All of those things are very painful for customers. These OEMs have been living through these busts and booms before, and they don't want to upset their customers too much. So they're all working hard to at least flatten out the timeline and if not improve it. And I'm seeing signs of that across the board. Today's timelines are in the lead times are in the four to five year range. Do I have that about right? I would say between 36 and 48 months, I suppose there are some OEMs that are claiming up to 60 months, but I would say on average, it's around the 48 month period. Got it. The other thing I'm curious about is size. There's obviously, it's not a monolithic market. Even within the power generation, there's different products that serve different use cases and at different scales. And I think the scale question is sort of an interesting one because the question is what's getting built or what is being designed to get built. Large scale generation, gigawatt scale type of stuff is the fact that data center is driving a lot of this, changing the desired scale of the end customer and what does that mean for the products in the supply chain. Good question. Well, I actually look at the market drivers. I think there's at least five major market drivers. And in each one of those market drivers, small, less than 20 megawatt gas turbines, turbines 20 to 100 megawatts are seeing a different set of dynamics. And then what I call jumbo sized units, which are 150, 250 megawatts and above those I call jumbo units. They're all being affected differently, driven by the different market drivers. And I say there's at least five market drivers in the marketplace. One is grid scale battery storage. Number two, cold plant retirements. Number three, grid scale renewable energy expansion. Number four, the development of rapid development of data centers and artificial intelligence exploitation or expansion. And then just the availability of natural gas and its affordability is I'd say the fifth driver. And if you look at each one of those different drivers, those three sized units are all being affected differently. And if you want, I could actually walk through each of the different drivers and then explain how each one of those three different markets are being affected. Yeah, I mean, it's interesting that you described that, right? Some of those drivers, I would think would be a suppressant on demand. So I agree. The growth of grid scale energy storage, right? Grid scale energy storage is sort of a gaspeaker replacement product on the grid, right? Predominantly. So I would presume that suppresses the market to some degree. But maybe are you saying it results in smaller units being developed on the grid? Or what's the dynamic? You're a great lead in the shell. Actually, you would think, just and generically, you think off your head, Oh, well, grid scale battery storage, that's got to drive down the demand for gas turbines. Actually, in some cases, the answer is exactly right, but not in all cases. So I mean, if you actually look at the market and what's happened with grid scale, I would say large jumble sized units. Absolutely. They are being it's a negative, it's a negative dynamic. If you look at gas turbines, say 40 to 100 megawatts, actually it's a it's an opportunity because there are several of the developers are counting on gas turbines to recharge or develop what I call hybrid systems that use gas as a when it's cost is low to spin up the gas turbine and recharge their grid scale battery storage. So they're not just relying on renewable energy to recharge their batteries. So, so and then when you look at the real small gas turbines, generally, they're not being quite as affected by the grid scale battery storage segment. But clearly, as you correctly pointed out, or you felt the intuitively, yeah, large power plants, jumbo units, it's a negative, but for gas turbines, 40 to 100 megawatts, it's actually a little bit of a positive influence. And then I imagine right, coal plant retirements, big projects coming offline, presumably get replaced with big assets, at least if you're trying to do one for one. So I assume it's that that is all things equal a positive signal for larger scale turbine. Yeah, for for coal plant retirements, it's really for all three segments, the the less than 20 megawatts, the 40 to 100, and the large jumbo, it's a positive influence, but mostly for the large jumbo units. But interestingly enough, you see a lot of mobile power and peaking units being installed as support for the grid where coal plant retirements are occurring. Well, you see that in the context of some of your other drivers, right? Like, I know of some projects that are coal plant is retiring, we're going to replace it with like a big solar plus battery installation. And then we probably need some smaller scale peaking gas to supplement that. Yeah. Right. It's like that kind of thing. Well, yeah, if you look at if you look at grid scale, renewable energy, I mean, the amount of grid scale activity is going up just explosively, it's expected to double in the next five years and the cost of a levelized cost of electricity for for solar power is way, way down. But so that has a negative impact on the large utility or jumbo size gas turbines. But but definitely it has a positive influence on mobile units, peaking gas turbines, just because when the when the sun goes down and the wind stops blowing, you know, you've got to have backup power. And those units, I would say from about 15 megawatts up to 100 megawatts are actually very good investments for, I call it, renewable offset. And when you mentioned the mobile thing, I mean, those types of installations, you don't necessarily, you're not looking for mobile generators. I think of the mobile generators as being a good fit for either like an off grid type application, you see a lot of this in the oil and gas world or for bridge power type situations where you're looking to this is what you see now where look, we need we need power now because we're building a data center and the grid connection is going to take three to five years. So we need a bridge, but we don't need it forever. Am I wrong to think that that's where the mobile power segment ends up? Well, you're not wrong, but you're not 100% right either because clearly when it comes to data centers and artificial intelligence, mobile power and even permanent onsite power is as a backup to the and supporting the demand for data centers is a very strong influence on both mobile power and permanent onsite units. But believe it or not, there's a lot of utilities who will buy mobile units. They'll put and they'll locate them in a what they call a grid sensitive area. And over the course of five to 10 years, they'll improve their infrastructure. And then they'll move those mobile units to another sensitive grid, grid sensitive area. And so the mobile power is just been a fantastic opportunity for basically three companies, solar gas turbines, the Division of Caterpillar, the GE, Vernova for their mobile units and for MHI arrow power for their mobile units. Those three players have done extremely well with mobile powered units for a variety of reasons, even in oil and gas. But for the reasons that you and I have just discussed in the last 10 minutes, absolutely. And I don't see that market going away at all. Yeah, if anything, it's getting supercharged by additional use cases as we've just absolutely, which gets to that sort of 100% on. Yeah, which gets to that sort of the one that seems to be the biggest net new thing that's happening right now, but like is is a huge deal is all the gas turbines being developed for data centers, whether mobile or stationary, right? But you see like, you know, there's that partnership between Chevron and engine number one where they've they've secured gigawatts worth of GE, Vernova turbines, they're going to go use those to develop a bunch of data centers. And then I'm not sure whether those are actually intended to be permanent or just bridge power. But like, that's one example amongst many. And it seems to me is the is the factor that's kind of tipping this market over the edge from just being a generally tight market to like a historically tight market. Yeah, well, you're making a good point. I mean, if you look at data centers, there's like 11,000 data centers serving the digital commerce and artificial intelligence community already around the world. And because they many of them have been around the average electrical loads around four megawatts. But there's like 1400 new data centers planned in the United States alone. And over 1000 of those are all large scale. They're going to need a lot more than four megawatts. I mean, some of those data centers, their electrical load is more than the community around them. Yeah, there's a there. I mean, it's just like, electric co op, I think it's Susquehana co op or something like that in Virginia, that like, I remember seeing some some filings and regulatory filing, where they were projecting their load growth to like more than double based on purely a couple of data centers that are coming into the territory. Yeah, in fact, you you just touched on a good point that whole region around Virginia, Washington DC, that whole area, there's more data centers in that area than anywhere else in the world. Right. It's just a mecca of data centers. But but these dynamics are really interesting around data centers. And I don't think it's going away. I think it's you see people using artificial intelligence more digital commerce is just booming and it's not going away. To me, two things can be true at the same time. I think it can be true that this is the demand from the gas turbine OEM perspective, the demand is real. The market will buy an enormous volume of new gas turbines to serve these markets. And that's also true, by the way, of like utilities who are trying to manage interconnection requests and so on. Like it can be true that that is real and also that we are in a speculative bubble on the development side, because there will not be, I mean, as you correctly said, there are a thousand large scale data centers in development in the United States. And I will state categorically, I don't think there will be a thousand new hyperscale data centers in the United States anytime soon. I don't think there's actually that much demand for it. So like both things are true. There's all these there are cowboys out there trying to take advantage of the moment. So the challenge, of course, then if you are on the supply side, whether it's a utility or you're a gas turbine OEM, is how do I make sure that the buyers I'm signing up with are real? And that gets to your point of like these big non-refundable deposits. If you have all the market power, that's sort of how you take advantage of it. So it seems like they're doing the right thing in that regard, at least. Yeah. Well, and the other dynamic to keep in mind, Shell, not only that is, it's not just one of these market drivers that's making things happen. It's all five of these market drivers that I've mentioned, including the price of natural gas, which is very affordable in the United States. So when you combine all of these what I call market drivers, it creates in a situation where these OEMs are relatively comfortable building out a supply chain strategy to support the market because they're not just relying on one dynamic. Back when I was executive at one of these large OEMs 20 years ago, we were basically counting on only one of those market drivers to happen and one of them didn't happen. And so it hurt our strategy. But now you have a situation where you have three to five key market drivers that are all paying the market. And so it creates a little bit of, I would call, risk comfort for the OEMs because they know it's not just one thing they're counting on to make the market move. Okay, final question for you, I guess, is on the technology side, is there any these are pretty mature technologies? Is there any significant innovation that either we have seen recently or that you expect to see in the next few years? Will the market change as a result of technological innovation or is this just a rinse and repeat and stamp them out as much as we can kind of a situation? Yeah, good question. I would touch on two areas. First off, all of the OEMs have spent an enormous amount of money trying to get, and they've been very successful in slowly increasing the efficiency of their combined cycle plants. I mean, it used to be combined cycle plants, average efficiency was about 55%. And they slowly crept it up to 60. And then they kind of hit a dead spot and they couldn't figure out how to get above 60. And then they started to evolve developing their, I'll call it a very holistic strategy to the power plant. So it wasn't just the gas turbine, it was the HRSG, it was a whole, all sorts of different technical factors that they were lovers that they were pulling to try and squeeze more efficiency out of their power plants. And they crept it up to 60. And they got to 60 and a half, 61, 60.3. I mean, they're starting to push 62% efficiency and more. And I don't think they're going to quit because if you look at the, if you look at the levelized cost of electricity, and that's a big factor that these utilities are using and assessing which OEM they're going to use, fuel is a big, big element in the levelized cost of electricity. So the more efficient, and the more efficient, the more effective that the OEM is in convincing that customer that they have a more efficient unit and even guaranteeing it, the better for them, they'll be more competitive. So efficiency is, it's not coming up by leaps and bounds, but it's a gradual increase over time. It's been quite remarkable, you've asked whether you got to hand it to all three of the major OEMs that they've been able to make some very significant improvements in efficiency, albeit very difficult. The second big area of technology development is converting their combustion systems over to using hydrogen. Now, I put all of that into a big, big set of quotes, because while they're all working on hydrogen, and they can, and they've all demonstrated to a degree some capability of operating in hydrogen, the biggest problem is where are they going to get it? The amount of hydrogen that you need to run one of these large jumble sized units, it's just an enormous amount of gas, and where are you going to get it from? So while they're all spending a lot of money, and their engineers are working very diligently and doing some fantastic development, I have some doubts as to whether the market will actually see a significant increase in purchases of gas turbines that actually are using hydrogen. But clearly, they're all working on it. Yeah, it's a, you know, the bet is if we build it, they will come. If we build hydrogen ready gas turbines, then the market will show up for them and the hydrogen will be there. And of course, it's a dynamic market for hydrogen at the moment. So we'll find out whether that plays out well for them. But good point on efficiency, it's like a steady grind, but it adds up a lot over time. Yeah. Tony, this was awesome. Really appreciate the time. Thanks so much for joining. Thank you. Tony Bruff is the president of Dora Partners in Energy and Gas Consultancy. This show is a production of Latitude Media. You can head over to LatitudeMedia.com for links to today's topics. Latitude is supported by Prelude Ventures. Prelude Backs Visionaries accelerating climate innovation that will reshape the global economy for the betterment of people and planet. Learn more at PreludeVentures.com. This episode is produced by Daniel Waldorf, mixing and theme song by Sean Marquand. Stephen Lacey is our executive editor. I'm Shale Kahn, and this is Catalyst.",
    "release_date": "2025-06-05",
    "duration_ms": 2404000,
    "url": "https://chrt.fm/track/G78F99/traffic.megaphone.fm/PSMI6893048605.mp3?updated=1749250187",
    "source": "Catalyst with Shayle Kann",
    "timestamp": "2025-06-15T02:01:06.169551"
  },
  {
    "title": "How geothermal gets built",
    "description": "Geothermal seems to be nearing an inflection point. With rising load growth, clean, firm power is more valuable than ever. Next-gen geothermal players like Fervo Energy and Sage Geosystems are signing PPAs with major tech firms. Even U.S. Secretary of Energy Chris Wright \u2014 a known critic of renewables \u2014 has praised the potential of geothermal.\u00a0\n\nThe size of the U.S. geothermal resource accessible through next-gen geothermal technologies like enhanced-geothermal systems is enormous \u2014 potentially thousands of gigawatts. But tapping into it hinges on figuring out the economics.\n\nSo what does it actually take to develop a geothermal project \u2014 and how are new tools reshaping the process?\n\nIn this episode, Shayle talks to Carl Hoiland, co-founder and CEO of geothermal energy company Zanskar, which uses AI for enhanced geothermal exploration. Shayle and Carl cover topics like:\u00a0\n\n\n  \nWhy geothermal stalled \u2014 and what\u2019s changing now\n\n\n\n  \nThe full step-by-step process of developing a project\n\n\n\n  \nHow to avoid exploration risk, also known as dry hole risk\n\n\n\n  \nMethods for estimating resource size and managing depletion risk\n\n\n\n  \nThe geothermal supply chain\u00a0\n\n\n\n  \nHow permitting is speeding up\n\n\n\n  \nCarl\u2019s outlook for when and where development is likely to happen\n\n\n\n\nResources:\n\nLatitude Media: Geothermal could meet 64% of hyperscale data center power demand\n\nLatitude Media: Why geothermal might benefit from Trump\u2019s tariffs\n\nThe Green Blueprint: How a text message launched a geothermal revolution in Utah\n\nLatitude Media: The geothermal industry has a potential ally in Chris Wright\n\nLatitude Media: Why California lawmakers are warming to geothermal\u00a0\n\n\n\nCredits: Hosted by Shayle Kann. Produced and edited by Daniel Woldorff. Original music and engineering by Sean Marquand. Stephen Lacey is executive editor.\n\nCatalyst is brought to you by Anza, a platform enabling solar and storage developers and buyers to save time, reduce risk, and increase profits in their equipment selection process. Anza gives clients access to pricing, technical, and risk data plus tools that they\u2019ve never had access to before. Learn more at go.anzarenewables.com/latitude.\n\nCatalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. See how EnergyHub helps unlock the power of flexibility at scale, and deliver more value through cross-DER dispatch with their leading Edge DERMS platform, by visiting energyhub.com.",
    "summary": "Latitude Media is hosting the Transition AI conference on June 12, 2025, focusing on energy infrastructure in the AI-driven load growth era. The event will bring together industry experts and feature live episodes with prominent figures from Google and Commonwealth Fusion Systems. Geothermal energy, particularly in the US, is discussed, highlighting its history, challenges, and potential for growth. The podcast delves into geothermal exploration processes, including drilling temperature gradient holes and assessing resources for temperature and permeability. The conversation underscores the importance of refining exploration methods and engineering solutions to drive geothermal energy development.",
    "transcript": " Mark your calendar for June 12, 2025. Latitude Media is holding its fourth transition AI conference in Boston. This year's theme, energy infrastructure in the era of AI-driven load growth. We're going to bring together investors, developers, researchers, and tech companies to talk about the creative ways to meet data center demand. And companies include FERVO Energy, Form Energy, Scale Microgrids, Spark Fund, KKR, Generate Capital, Orenia, FlexGen, National Grid Partners, and more. Plus, we're going to have a live open circuit episode featuring Caroline Golan from Google, and a live green blueprint episode featuring Rick Needham from Commonwealth Fusion Systems. Get your ticket at latitudemedia.com slash events, podcast listeners, get 10% off their ticket, use the code latitudepods10 at checkout latitudemedia.com slash events. We will see you at transition AI. Latitude Media, covering the new frontiers of the energy transition. I'm Shail Khan, and this is Catalyst. When you look at the full stack of kind of near-term EGS and conventional, we really are talking about hundreds of gigawatts to terawatts of resource potential. There's much potential to give as, say, the entire Gulf of Mexico from an oil point of view. Coming up, the heap beneath our feet. Do you want instant access to energy storage supplier pricing that's project-specific, or the ability to compare domestically-made battery and PCS options across the market? Anza now offers the industry's first battery energy storage data and analytics platform to make better development and procurement decisions. Anza provides in-depth commercial, technical, and risk data and analytics to help developers choose the best equipment for any project. Improve your returns and save months of evaluation time with Anza. Learn more about Anza's energy storage subscriptions at go.anzarenewables.com slash latitude, or click the link in the show notes. Imagine a world where connected devices like EVs, home batteries, and smart thermostats work together to support a more efficient and reliable power grid. Well, you don't have to imagine it anymore. This vision is a reality today, thanks to Energy Hub. With Energy Hub's Edge Derm's platform, utilities can create virtual power plants through customer-centric flexibility programs, making it easy to manage distributed energy resources and balance the grid. Unlock grid flexibility and reliability through cross-DER management with Energy Hub, the trusted Edge Derm's leader. Visit energyhub.com to learn more. I'm Shail Khan. I invest in early-stage climate technologies at Energy Impact Partners. Welcome. So, is geothermal having a moment? Here's the case for its clean-firm base load power, which is a hot commodity right now. Hyperscalers of all expressed interests, some of them have signed PPAs. Fervo Energy notably has PPAs, both with utilities and with Google for hundreds of megawatts of new development. The Trump administration, in particular to the Secretary of Energy, Chris Wright, came into office with very positive rhetoric about geothermal, in contrast to other forms of renewables. The case against is the big, beautiful bill that just passed the House last week, which throws the geothermal baby out with the wind and solar bathwater, basically. So, all of that enthusiasm is not currently reflected in legislation, at least, though, let's see what happens in the Senate. Anyway, I think regardless, the case 4 is a lot stronger than the case against here, to be honest. And so, I wanted to bring on Carl Huyland to talk a little bit more about geothermal at a high level. Carl is the CEO and co-founder of Zansgar, which is a startup that's leveraging AI to enhance geothermal exploration and ultimately production. But beyond that, Carl is basically an encyclopedia of geothermal, as you will soon see, and I have taken great advantage of that myself. So, it's your turn. Here's Carl. Carl, welcome. I shall. It's great to be here. All right. I want to start with you giving me a history lesson, as you have given me before. But walking through the history of geothermal power in the United States, in brief. Fantastic. So, humans have been using geothermal energy for many purposes for a long time. But, really, you see the origins of this power industry emerge in the United States in the 1960s, with the initial development being in the geysers field in Northern California. And it's really ushers in this early mover experimentation phase. You start ushering in this new phase of early geothermal developments, and they're really exploring for the first time the ability to use this resource to generate electricity. And it's fairly basic at the time. Just take the steam that's coming out of the ground, drive it through a steam turbine to generate electricity. And usually, they were evaporating it at that point. But we see it. Most of the United States growth actually happens in those first one to two decades. And for a while, it looks like geothermal is just going to take off. It's scaling faster than any other renewable at the time. And through the 1980s, we had gigawatts of capacity in the United States. But then, things kind of come to a halt. And you go through this period through the 90s and 2000s, where you really see almost no growth. And then another tip up in the late 2000s, early 2010s, and then it's been flat almost until just recently. And even that tip up in the late 2000s and early 2010s, how much did we build during that period? We added hundreds of megawatts, but they were really in some ways offsetting some of the losses that we saw in some of the early steam fields. And so in terms of total installed capacity, it's meaningful, but it's relatively minor, and not as much as we were hoping. I think a lot of people know this to be true of nuclear. We built a lot of it decades ago, and then we stopped building new stuff in the US. I think a lot of people don't appreciate that the same thing is true of geothermal, and actually, interestingly, on a roughly similar timeline, which I find kind of intriguing. Not exactly the same, but similar kind of story. So what happened? Why did it stall out? Well, I think there were a couple of things that happened in the early days. The early technologies could really only work with very high temperature steam. And so they were looking for exceptional locations in the Earth's crust, where this was 200 Celsius and often higher. And it turns out those were relatively rare. And the further down in temperature, you go the more abundant they become. But the other part of it is that we had so many failures in trying to drill into these resources, where there was a hot spring or geyser at the surface. They thought this was a no-brainer. And when they come in and started drilling those deeper wells, they would not find the resource they were expecting. And so this is what we call exploration risk, or dry hole risk in geothermal. And it led the industry to start having enough failures to scare capital investors to say, whoa, should we really be throwing more money after this? And this kicks off really a race, a lot of it funded by the Department of Energy, to solve the problem in one of two ways. We were either going to get better at finding these systems, so better exploration methods and data types, or we were going to avoid the exploration problem altogether by just engineering in place the things that we needed to make that system work. And so you see the beginnings of both the unconventional enhanced geothermal industry starting at that time, as well as the beginnings of some of the modern exploration methods. Before we talk about the process of exploration and development and so on, from a technical standpoint, what is happening there? What is going on when you have steam at the surface, what looks like it should be a perfect resource, and then you drill down, and it's a dry hole? What's actually going on under in the subsurface? Yeah, so at the geology or geothermal one-on-one level, everywhere on the planet is you go deeper. It gets hotter, usually, or at least in general. And in most places, that's, let's say, 25 Celsius per kilometer. So you'd have to go four or five kilometers or so to get to where you'd have steam temperatures. But in certain locations, that temperature is actually elevated, either because of magnetic or volcanic processes that may have brought heat closer to the surface, or in many places in the western United States, even in the absence of volcanism or magnetism, you can have fractures or permeable zones within the earth that will allow it to start convecting hot water from greater depth to closer to the surface. And hot springs are usually that kind of manifestation where there's hot water circulating, often in a convective nature, to bring that water to where you see it. What we've since learned in the decades since is that where you see hot springs at the surface, those are kind of the outliers. That's the tip of the iceberg. Most of these convective cells of hot water underground are not coming to the surface. And we now know that the majority of them are actually what we call blind. There's no hot spring, no volcano, and you wouldn't have even known they existed had you not, in most cases, drilled into them accidentally. And so with the Geyser's projects, for example, which by the way, is still producing power, some of them, right? It's amazing. It's a great resource. We just kind of got lucky in that case, was that just such a good resource? I guess what you're saying is that most of the good resources do not show at the surface, and many of the things that show at the surface are not actually good resources. Is it just that that first time around in the Geysers, it just happened to be the overlap? I think that's exactly right. And so the first pass, and this is true for almost all natural resource industries, the first pass is the low-hanging fruit. The really obvious stuff at the surface. There's copper, there's gold, there's steam, there's oil seeping out, let's drill there. And the Geysers was just one of those world-class resources. And there may be more of those around the globe yet to be developed, but at least here in the United States, it's unlikely that there's another gigawatt scale conventional geothermal resource to be discovered of that type. But there, you're right, there were Geysers at the surface fumaroles. In fact, the early explorers, a lot of them came from oil and gas. You had chevron, unical, phillips, hunt, and others that entered into the space in the late 70s and early 80s, and they actually spent hundreds of millions of dollars going out and drilling test holes, looking for more Geysers-like fields. And the Geysers was such a unique field in terms of its size and scale. They thought, oh, we just have to drill every few miles, and we'll see something like that if it's out there. And it turns out they didn't find anything like that in all of their searching. But in the process, they did find some of these other geothermal systems, some of which are now being turned into EGS fields, and some of which are being developed for conventional. I think they just underappreciated how narrow and small they could look at the surface and yet still have meaningful power potential of depth. Can you just give a little bit more detail on the difference between a conventional or hydrothermal field and an EGS field? What are you looking for in each? Yeah, in a conventional geothermal field, you need to find the temperature. So it needs to be hot enough to boil water or working fluid. You need to have porosity or permeability in the rock so that that fluid can circulate through, extract heat, you'll bring it out at the surface, then you'll re-inject it so it can circulate again. And you need water. So that working fluid that's going to sweep that heat through the system. And in the conventional field, all of those exist naturally. That's what we call a hydrothermal system. EGS was based on that early recognition that we drilled a lot of holes or wells that were hot but didn't necessarily have the water or the porosity and permeability to be able to circulate the water. And EGS was this hope that we could stimulate or engineer the rocks to have that permeability and maybe even add the water in some cases. And so this in many ways, I think, is analogous to what you see in oil and gas. The division between conventional oil and gas and unconventional is the ability to just drill a well and have what you need versus needing to modify the subsurface in some way. Okay. So the failing, the reason that the market stalled out, was we weren't great at exploration at the time. It turns out we sort of lucked into some great resources and in geysers and then couldn't replicate that success. And in the process of failing over and over again to replicate that success, it became harder and harder to finance new exploration. And then everybody kind of just fell out of love with geothermal. Now, obviously, we have these resurgence and as you said, it's coming in sort of two different categories. One is the, can we do better at finding the existing hydrothermal resources? And then the other is, can we engineer them via EGS? Let's talk about conventional hydrothermal development. Can you kind of walk me through what that like the actual steps in the exploration and then development process? And when you said they drilled a bunch of test wells, what is a test well? What does it cost? Like what is, you know, right? Yeah. So the first thing you're usually looking to confirm is temperature. You want to see that there's a resource here with enough heat in place to make a meaningful resource. And the standard tool of the industry is what's called the temperature gradient hole. And so you're literally going out and drilling a hole into the ground. Sometimes it's 100 feet, might be hundreds of feet or a thousand feet. And you're going to come back and measure the temperature gradient in there. And based on those gradients, estimate how much heat is in place and what might be at greater depths. One question I've always had about this, um, you ultimately, if you're finding a resource, you're going to be drilling deeper than 100 feet or 1000 feet. So it must be true that the temperature gradient that you find even pretty near the surface is highly correlated. It's like the temperature gradient is a spectrum that is consistent. And so you can infer from 100 foot depth well, what the temperature gradient, what the temperature expected would be at a kilometer or something like that. Is that right? I think directionally, it's right in that heat has a harder time hiding than other types of resources. Say like oil that might be underground. And so it is diffusing through the rock. But there are geologic processes that can obscure that or make it difficult to see. You might have a lot of cold water sweeping through from the climate or rainfall in an area that obscures the surface of it. And so there's large parts of Idaho, for example, where there are deep geothermal resources that you don't see at all in the first few 100 or even 1000s of feet because of that obscuring. But in drier areas, yes, you're right. You'll often see pretty distinct anomalous caps above these systems. Okay, so you drill this temperature gradient whole, and that's presumably pretty cheap to do. You're not drilling that deep and depth is the main cost of drilling. And you're not drilling, you're not putting casing or anything like that, you're basically just drilling a hole with a sensor measuring temperature gradient. So I assume that that is a lowest cost part of exploration, at least a physical lowest cost. In terms of the drilling to really confirm a resource, before that you will have deployed even lower costs, shallow and geophysical methods, to help you identify the areas that are worth drilling. But at this point, if you're drilling temperature gradient holes, you're deploying tens of thousands, maybe hundreds of thousands of dollars to test a certain target area. Catalyst is brought to you by ANSA. ANSA offers a one-of-a-kind data and analytics platform and advisory services to support better project development and procurement decisions. For energy storage developers, ANSA's platform provides crucial information that you never had easy access to before. Now at your fingertips is real-time pricing for a long list of system configurations to suit any project. ANSA provides a 360 degree view of the market with a life cycle cost analytics in commercial, technical and risk data. With ANSA, developers can easily determine which products to use in their designs, finance models and RFPs. Learn more about how ANSA helps save time and maximize profit at go.ansarunuables.com slash latitude. Catalyst is brought to you by Energy Hub. Energy Hub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. The Energy Hub platform takes the guesswork at a balancing energy supply and demand. It uses machine learning to control customer-owned distributed energy resources like EVs, home batteries and smart thermostats to precisely shape load profiles for grid flexibility and reliability. As the industry leader, Energy Hub helps more than 80 utilities manage 1.6 million devices. That's more than any other edge derms on the market. Click the link in the show notes to learn more or go to energyhub.com. You drill your first well, which is your temperature gradient hole. How easy is it? Is it binary? I assume it's not binary. What is the... So how much art versus science is there in the interpretation of that data? Is it easy to determine go no-go or do you have to do something sophisticated? In the early days, there was a lot of uncertainty. There really just weren't enough success cases or even failure cases to help them understand what some of these data types meant. They often use very high thresholds. If it's not boiling, I'm not interested. Increasingly over time, our experience has taught us, like you said before, that even a semi-anomalous or readings at a shallow level might indicate that it's worth drilling deeper. It's often an estimation of, given what I know now, is it worth investing additional capital to drill into that resource at greater depth, to gain greater confirmation. You can start with some probability distribution of possible outcomes. In the deeper you go, and the more capital you invest in the project, the tighter that distribution of outcomes becomes, and the higher your confidence is and what kind of resource you're working with. Okay. So let's say you drill your temperature gradient hole, you confirm you see what you're looking to see, and at least your interpretation is positive there. What's the next step? At that point, you're going to need to put together, if you haven't already, a pretty detailed conceptual model or understanding of what might be driving the system. Is it a volcanic system? Is it a sedimentary system? Is it a fault-hosted system? And that's going to give you a better predictive ability to go deeper into the resource, at least with classical methods here. And you're ultimately going to then want to say, okay, if I've proven temperature, now I need to prove permeability, or the ability to flow water through the wells that I would drill here. And so you're going to step up in size and complexity of your drilling program and drill slim wells, or small, you think of those mini production wells, that are going to be able to allow you to pull water out of the system. At which point you're flowing, like you leave that well open for a while and flow it, presumably. Is this when you're also able to start to determine what a decline curve would look like, or is this too early for that? It depends on how well you engineer, how large that well is, but the initial step is just showing that you can flow it at commercial scale. And then what you really want to do is be able to flow it long enough to run a flow test and indicate that over time it's not declining too fast, and that you'll be able to manage this resource sustainably. And like rough order of magnitude, what is the cost of one of these wells? And depth. Yeah, in this case, you're going to be going to a few thousand feet, maybe as much as five or six thousand feet. And your cost is going to be in the million plus range. So call it one to two million, maybe three or four, depending on the more complex wells to prove that out. So this is where you, I presume, like historically, when it became more difficult to finance, the cost of capital got higher and higher. This is the step where like real money starts to show up. I would assume. That's right. At this point though, you also have a little more confidence because of your earlier drilling and exploration. So your conversion rate is also a little bit higher. And so yes, you're putting more capital to work, but you're a little more confident it's going to be worth it. Those earlier stages, it is less capital, but you have to pursue more projects in parallel, which all sum up to also meaningful amounts of capital. But when we talk about dry hole risk and what happened historically and so on, is this the stage where the dry hole shows up? Basically, I mean, you might have gotten your temperature gradient, but then you drill down and you can't flow anything. Yeah, you would start seeing it here. And actually, in the early days, they would often skip that intermediate and what I was calling a slim well or more miniature well, and they would go straight to production well. We've got great temperatures, let's drill into this and they might drill the five, 10, 15 million dollar well, only to realize that there was no permeability or porosity in the rock. And we call that a dry well. So hot, but dry, no water coming through it. Okay, so next step. So you drill this well, you're able to flow, you confirm permeability and porosity, you've confirmed temperature. Are you de-risked at this point? Do you know what you've got? You're much further along the route of de-risking, but until you can also drill the injection well, which is going to be the way that you reinsert that water back into the system and let it circulate through the rock or through the ground network, you're not actually going to know that full decline rate to be able to build a robust reservoir model or estimate of the long-term potential of that resource. Can you describe what I know I brought up decline rate, but I realized we didn't describe what causes it. What causes the decline? Like, you could imagine a scenario where, look, it's hot underground, you just keep recirculating water and it should work infinitely. Why doesn't it? Yeah, so you are pulling heat out of the system, right? You're taking that to the surface, you're extracting it either through your turbines or through heat exchangers. And when you re-inject it, the water is going to be a little bit colder or quite a bit colder. And because of that, it needs to extract more heat from the rock before it returns to the production well. And you can think of these two wells. If your injection well is too far away, it actually might not ever return and you can start to draw down the pressure in the reservoir. If it's too close where it maintains good pressure in that reservoir, it might return too quickly. And you could think of that as then not having enough time to recharge in temperature. And part of the challenge was finding that optimal distance where it has enough time to fully recharge while also maintaining pressure in your system. Right. And then kind of moving ahead in the development process, I imagine that the other challenge related to that is, okay, so let's say you're successful, you drill your production well and your injection well, and it's working. Actually, give me context here. How much power might you generate out of a single pair? Let's see. So we recently actually drilled a new production well operating power plant in New Mexico. And that single well, the larger diameter well, going to about 8,000 feet depth, and it can produce about 15 megawatts net. So enough to power about 15,000 homes day and night. That's sizable. 50 megawatts is sizable. But ideally, probably you want projects that are multiples of that size or in order of magnitude bigger. That's right. In an ideal world. So in order to do that, now you're drilling another pair. And I presume if you're drilling another pair into that same reservoir, you're obviously extracting even more of the heat. And so I assume there is a fair amount of magic in the question of how close together can you put well pairs, first of all, and second of all, basically, how much can you extract from a given resource without accelerating the decline? Yeah. And this is an area of research and really just resource understanding that matured a lot over the past few decades as the industry was dealing with their existing resources and looking to expand or preserve them. And this is really where reservoir modeling becomes key. So there's certain data types like your flow and pressure information, but also we can put trace chemical tracers into the wells that will help identify how long it takes for them the water to return from injection to production. And based on these, we can build pretty robust models that are bankable in terms of the feasibility that they provide. And this is where you can start to estimate if I had two or three or four wells here, how much will that impact my decline versus just doing one or two in the same location? Okay. So this is the end. I mean, you drill the well pair. It works. You drill your however many additional well pairs you're going to drill. Now you've got a resource. What are you putting topside? We haven't talked about that yet. You get the heat out, but obviously heat is not the end of the story. Could be the end of the story, I suppose. Is anybody done just geothermal, like ground geothermal for, I guess, ground source heat pumps are this, but... And the most shallow ground source heat pumps. But in terms of direct use geothermal, there are a number of locations around the world that do use it in a direct way. In Europe, they're looking to repower many district heating systems by just bringing in hot water from underground. And even in the United States, the city of Boise, the city of Klamath Falls, they've been running district heating systems with geothermal where they're just directly taking that heat. At Zanskar, at our company, we're actually working with large mining companies now to also provide heat for industrial applications. And so I think there's a lot of exciting applications there, even before you convert to electricity. Okay. But let's assume you do want to produce power, which is what most of the projects end up doing. What is the topside infrastructure that you require? The topside, in many ways, looks like many other thermal plants. You're taking heat, you're generating steam, and that steam is going to drive a turbine, which then drives a generator and puts electricity onto the grid. In geothermal, especially in the western United States, oftentimes we're working with such a low temperature starting fluid that it's more efficient to put that heat into a working fluid, something that boils at a lower temperature. So think of isobutane or isopentane. And for that, we actually use heat exchangers. So most modern systems are going through heat exchanger. We call this binary. And then that working fluid on the other side goes through the turbine system. And you re-inject your fluid back into the ground. And that working fluid just cycles through the system. Okay. So I think we've reached the end of the development process. I'm curious about the timeline, both historically and maybe today. We're in an interesting moment now where there's plenty of demand for new power period, new sources of generation period. And then in some circles, particular demand for clean firm, which is what geothermal is. But everything is slow right now. It's hard to get anything fast. The fastest thing you can get maybe is renewables. But even that is gummed up by supply chain challenges and all sorts of tax credit issues and so on. But gas turbines are backordered for five years. Nuclear takes nuclear timeframes. What is the time frame of exploration and development for geothermal historically and how much opportunity is there to compress it? Historically, it was also a fairly long lead time type development. Historical projects took usually over five years and oftentimes as much as 10 years from start to COD. And major part of that is the slow decision making. As I mentioned, the incremental de-risking of a resource. We collect data, go back to the drawing board, decide if we're going to move forward. But another part of it was the permitting timelines is that a geothermal development project would have to go through five NEPA reviews if on federal lands. And the ability to accelerate a lot of that permitting is another area where we're seeing a lot of progress in the industry. Geothermal was recently given a categorical exclusion for the exploration activities of confirming and verifying a resource. And there's potentially still permitting reform ahead for the construction stage of the project. If you just take it down to the bare bones of you need about one to two years to explore and confirm the resource, and about one and a half to two years to construct that power facility and tie it into the grid. So the ideal scenario would be three to four years is realistic. And we're now seeing that as a possibility in certain locations in certain states where the regulatory frameworks are clear enough. And an example, not necessarily the Greenfield build, but of at least being able to come in and do meaningful work in a short period of time is work that we did recently in New Mexico. So we acquired in May of last year the Lightning Doc geothermal field, which is a field that had in many ways I think been seen to have underperformed and was no longer believed that it had much upside left in it. We based on data sets that we had and the models that we had really came to a conviction that there was a lot more there to give. And so shortly after acquisition, we permitted engineered, designed, and constructed a new production well to a zone that was four times deeper than the prior production zone. We built new pipelines, the electrical, installed the new line shaft pumps, and we were able to tie that into the grid in less than 12 months from acquisition. So in certain locations, we can actually move pretty quickly. And in our Greenfield projects, we have several that are in areas where we believe four years is a realistic timeline to bring those projects online. So you mentioned locations. I mean, that's the last thing that I want to talk about, I guess, with you, which is, talk to me a little bit about the history. I mean, we talked about geysers and geysers in California, but actually most of the geothermal that has been developed historically is not in California so much as Nevada and places like that. What's your view on how much geographic expansion should we be expecting for this next wave of geothermal development? How wide is the geographic aperture that people are looking at? Yeah, I think in terms of right now, the technologies that work today and that are on the precipice of commercial scale up in just the next few years, which is really conventional hydrothermal and EGS, we really think you're still going to be limited to tectonically active areas or areas with higher heat flow. And that's about a third of most continental land masses. So think the Western Third of the United States and many other tectonically active areas around the globe. And the main reason for that is because even with EGS or with conventional, you're still drilling as a primary cost driver. And if you can find that heat closer to the surface, it's going to have meaningful impact on economics. As drilling costs come down or as demand for clean firm power continues to increase, we see the economic shifting to where you could start to justify new build geothermal using some of these new methods and even more unconventional locations. We think that timeline could be on the order of decades though. Can you give me an order of magnitude of how much power we might... Well, let's say we stay in the Western Third of the United States. What's the total resource size that we expect? When you look at the full stack of kind of near-term EGS and conventional, we really are talking about hundreds of gigawatts to terawatts of resource potential. That to me is super exciting in terms of the United States' unique resource potential because you can think of this as a resource that has as much potential to give as say the entire Gulf of Mexico from an oil point of view. This is a real national treasure. And even just focusing on the conventional geothermal resources that I mentioned before, which is where a lot of our near-term work has gone, there are tens of gigawatts. And by some estimates, 100 gigawatts or more of that, which can have a meaningful dent right away without any first-of-a-kind technology risk. And so in terms of adding low-cost firm renewable energy in the next five to 10 years, we really think there's a chance to add more with geothermal than any other competitive form. All right, Carl, always appreciate you schooling me on geothermal. Thank you so much for joining. Thank you, Shale. Great to be here. Carl Hoyleand is the co-founder and CEO of Zanzcar. This shows a production of latitude media. You can head over to latitudemedia.com for links to today's topics. Latitude is supported by Prelude Ventures. Prelude Bex Visionaries accelerating climate innovation that will reshape the global economy for the betterment of people and planet. Learn more at PreludeVentures.com. This episode was produced by Daniel Waldorf, mixing and theme song by Sean Markwand. Stephen Lacey is our executive editor. I'm Shale Khan, and this is Catalyst.",
    "release_date": "2025-05-29",
    "duration_ms": 1981000,
    "url": "https://chrt.fm/track/G78F99/traffic.megaphone.fm/PSMI1880502245.mp3?updated=1748466184",
    "source": "Catalyst with Shayle Kann",
    "timestamp": "2025-06-15T02:04:49.317769"
  },
  {
    "title": "What to make of Trump's deep-sea minerals push",
    "description": "In April, the Trump administration issued an executive order to accelerate the development of deep-sea minerals \u2014 part of its broader push for \u201cenergy dominance.\u201d The world\u2019s oceans hold vast, untapped deposits of critical minerals like nickel, copper, manganese, and rare earth elements \u2014 all essential to batteries and clean energy technologies.\n\nDespite decades of interest, no commercial deep-sea mining project has begun production. The reasons? Regulatory uncertainty, environmental concerns, and the complexity of processing polymetallic nodules.\n\nSo what does this new executive order actually do?\n\nIn this episode, Shayle talks to Hans Smith, president and CEO of Ocean Minerals, a company participating in exploration of the Cook Islands. Shayle and Hans cover topics like:\n\n\n  \nWhat the Trump executive order mandates \u2014 and its legal limits\n\n\n\n  \nThe bottleneck of U.S. deep-sea exploration\u00a0\n\n\n\n  \nThe controversy about U.S. legal authority over international waters\n\n\n\n  \nThe economics and geopolitics of deep-sea hotspots like the Clarion-Clipperton Zone, Japan, and the Cook Islands\n\n\n\n  \nThe technical challenges of refining polymetallic nodules\n\n\n\n  \nCapEx, OpEx, and barriers to commercial deployment\n\n\n\n\nResources:\n\n\n  \nCatalyst: Mining the deep sea\n\n\n\n  \nWorld Resources Institute: What We Know About Deep-Sea Mining \u2014 and What We Don\u2019t\n\n\n\n  \nReuters: Trump signs executive order boosting deep-sea mining industry\n\n\n\n\nCredits: Hosted by Shayle Kann. Produced and edited by Daniel Woldorff. Original music and engineering by Sean Marquand. Stephen Lacey is executive editor.\n\nCatalyst is brought to you by Anza, a platform enabling solar and storage developers and buyers to save time, reduce risk, and increase profits in their equipment selection process. Anza gives clients access to pricing, technical, and risk data plus tools that they\u2019ve never had access to before. Learn more at go.anzarenewables.com/latitude.\n\nCatalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. See how EnergyHub helps unlock the power of flexibility at scale, and deliver more value through cross-DER dispatch with their leading Edge DERMS platform, by visiting energyhub.com.",
    "summary": "Latitude Media is hosting the Transition AI conference in Boston on June 12, 2025, focusing on energy infrastructure in the AI-driven load growth era. The event will bring together industry experts, investors, and tech companies like FERVO Energy and Form Energy to discuss innovative approaches to meet data center demand. The podcast highlights the potential of deep sea mining for battery minerals and discusses the impact of President Trump's executive order on deep sea mining in US waters. The conversation with Hans Smit from Ocean Minerals explores the challenges and opportunities in deep sea mining, emphasizing the need for regulatory framework improvements. The Cook Islands and Japan are leading in deep sea mining exploration, with companies like Mahana Minerals progressing towards mining licenses.",
    "transcript": " Mark your calendar for June 12, 2025. Latitude Media is holding its fourth transition AI conference in Boston. This year's theme, energy infrastructure in the era of AI-driven load growth. We're going to bring together investors, developers, researchers, and tech companies to talk about the creative ways to meet data center demand. And companies include FERVO Energy, Form Energy, Scale Microgrids, Spark Fund, KKR, Generate Capital, Orenia, FlexGen, National Grid Partners, and more. Plus, we're going to have a live open circuit episode featuring Caroline Golan from Google, and a live green blueprint episode featuring Rick Needham from Commonwealth Fusion Systems. Get your ticket at latitudemedia.com slash events, podcast listeners, get 10% off their ticket, use the code latitudepods10 at checkout latitudemedia.com slash events. We will see you at transition AI. Latitude Media, covering the new frontiers of the energy transition. I'm Shane O'Con and this is Catalyst. You know, there's this perception that the EOS been signed and this is a, you know, it's like flipping a light switch. All of a sudden it's going to go from nothing to everything. What this action has done is that it's taken DSM and put it into the spotlight. Coming up, going deep underwater for energy dominance. Do you want instant access to energy storage supplier pricing that's project specific? Or the ability to compare domestically made battery and PCS options across the market? Anza now offers the industry's first battery energy storage data and analytics platform to make better development and procurement decisions. Anza provides in-depth commercial, technical and risk data and analytics to help developers choose the best equipment for any project. Improve your returns and save months of evaluation time with Anza. Learn more about Anza's energy storage subscriptions at go.anzarenewables.com slash latitude or click the link in the show notes. Imagine a world where connected devices like EVs, home batteries and smart thermostats work together to support a more efficient and reliable power grid. Well, you don't have to imagine it anymore. This vision is a reality today, thanks to Energy Hub. With Energy Hub's Edge Derm's platform, utilities can create virtual power plants through customer-centric flexibility programs, making it easy to manage distributed energy resources and balance the grid. Unlock grid flexibility and reliability through cross-DER management with Energy Hub, the trusted Edge Derm's leader. Visit energyhub.com to learn more. I'm Shale Khan. I lead the Frontier Strategy at Energy Impact Partners. Welcome. All right, so it's been a couple of years, I think, since we talked about deep sea mining here. So here's a quick reminder of why it's interesting. At the bottom of the ocean, in certain places, there appears to be an enormous volume of these golf ball-sized rocks. They are polymetallic nodules, and they appear to be basically a rock full of battery minerals, essentially. I think nickel, cobalt, a lot of manganese, and copper. And in some cases rare earths as well. And there are literally trillions of dollars worth of these rocks just waiting to be hovered up and used to displace terrestrial mining. But for at least four things, one is a regulatory regime that doesn't fully exist yet for exploitation of deep sea mining, at least in some locations. Second is a heated battle over the environmental impacts of extraction. Third is the actual CAPEX technology and resources it's going to take to do it. This is mining, it's not cheap. And fourth is what you do with it once you get it, i.e. refining. Anyway, one thing that wasn't on my bingo card when we talked about this a couple years ago was that President Trump, in his second term focus on energy dominance, would find his way to deep sea mining and issue an executive order intended to speed up the market, at least for the United States. So for this one, I brought on Hans Smit, who is the president and CEO of Ocean Minerals, one of the companies that is exploring for deep sea minerals in the Cook Islands currently. Here's Hans. Hans, welcome. Thank you. Let's start by talking about this Trump executive order on deep sea mining that came out a few weeks ago. Now, maybe start by just explaining what's in it. Well, I think the key important thing about the EO is the fact that the US has now publicly come out and said that it supports looking into deep sea mining and has directed the US government to take positive and proactive action to help get this off the ground. I think that's the big thing that that executive order is done. And I think the other important thing about the executive order is that it has stipulated that it's not just US territorial waters. This is international waters as well as other exclusive zones. So what Trump has come out and said is, let's look at deep sea mining as part of the solution, but let's not just focus on US areas. Let's look at all projects and see how we can use them to solve this problem we have with critical metals. Which has become a bit of a point of contention, the part about operating outside of US exclusive economic zones. Maybe that's a good opportunity to step back for a second. Can you walk through the different regions where there is deep sea mining exploration or potential production to be had and where the authority and control over them sets? Yeah, essentially the two areas. You have the exclusive economic zone, which is the territorial waters of any country. So it's that country sovereign waters and the country's sovereign right to do whatever they decide to do within that region. And then we have what is known as beyond national boundaries, which is international waters. So those are all the areas outside of the exclusive economic zones. And the key difference between the two is during in an exclusive economic zone. It's the work that anybody does is subject to the rules and the law of that country. When you go into international waters back in 1984, uncloss, which is the United Nations law of the sea was ratified. And that is now under the auspices of the United Nations. And I think there are about 136 countries that have signed up to it. However, the US has not signed up. They have not ratified that. And in the international waters, it has been deemed since the signing of uncloss that that would be regulated by the United Nations and specifically the ISA, which is the international sea bit authority. And so that's where a lot of the, you could tell me if I'm wrong on this, but a lot of the early activity in deep sea mining world has been in international waters, particularly in this area called the Clerian Clipperton Zone. Is that because the understanding is that the resource is especially attractive there? Is that just because international waters, ISA regulation has been attractive to go after? Yeah, look, I think it's been done there because countries wanted to be sure that they didn't not mess up. So in a sense, there was a fear of missing out. So when that got ratified, all the major nations throughout the world made sure that they staked their claim. And they were participating in what was being released under the ISA. What happened when you stake your claim and you now take responsibility for that area, the onus is on you to execute a certain amount of work on that area. You cannot just sit and squat in the land. You need to show that you make in progress. So I think that was why there was a lot of work done in the Clerian Clipperton Zone. Also, a lot of that work was funded by governments. So there was a source of funding that was available to make sure that that work happened. And that work has been invaluable. You know, since 1984, there's been a lot of exploration work there. There's been a lot of money spent there. The European Union has spent a lot of money developing technology and equipment, so have the Chinese. So I think in general, it has been incredibly positive and incredibly useful for underwater mining specifically in that region. And giving us a good understanding and serving as a great foundation for developing guidelines and procedures and methods for doing this type of thing. Okay. So back to the EO. The EO pertains both to the US exclusive economic zone where there had been very little activity prior to this, as I understand it. So I'm curious what you think this might actually result in. But then is it essentially saying beyond US exclusive economic zone, this is the Trump administration saying we are interested in deep sea mining exploration and production. And we have not signed on to the treaty that would make us a part of the international seabed authority. And so we're sort of competing with the rest of the world for those resources. Is that the right way to think about it? I think there are two parts to that question. Firstly, the EO says exclusive economic zones are not only of the US, but in any country. There are other countries, Japan, Cook Islands, Papua New Guinea, who currently are actively working in their exclusive economic zones developing these resources. In the US, there hasn't been very much, if any, work in the exclusive economic zone of the US. But that is due to a regulatory issue rather than anything else. And then with the EO saying in international waters as well, this is where things start becoming a little more vague and a little more challenging. As you would note in the press, since that has been announced and the metals company have indicated that they want to use the EO and apply for licenses through the US laws to mine in international waters, there's been some surprise and there's also been some resistance to that. And I think this is something for the lawyers to get into and figure out how the metals company and the US with the EO are going to go and work in international waters without taking into consideration the precedent and the regulatory authority of the international seabed authority. So I think there's still a lot of stuff to be worked through and a lot of issues to be resolved in international waters. But in exclusive economic zones, it's pretty clear. They are laws in the US that allow companies to go and apply for expirational mining licenses. However, the current structure of the legal framework in the US is not very encouraging. So we as a company, for example, are not inclined to explore in US territorial waters because our investors are not given the kind of assurances and rights that we would get in other areas that would allow us to get a return on an investment if we were to spend tens of millions of dollars. So that raises this obvious question, which is, is this EO, we don't have to talk exclusively about the US because it is where the minority of activity is going. But just because there is this recent EO, is it going to do anything? Are there other factors that are stopping the US from doing serious exploration for deep sea mining that this doesn't change? And so as a result, it's just going to be sort of a piece of paper. I don't think it's going to be a piece of paper. I think the EO has got incredible value and has got incredible merit. But I don't think it's necessarily going to be the solver bullet that certain people think it's going to be. There's this perception that the EO has been signed and this is a, it's like flipping a light switch. All of a sudden it's going to go from nothing to everything. It's very rare that that is the occurrence of this type of action. What this action has done is that it's taken DSM and put it into the spotlight. It has brought the world's attention to a nascent industry that up until the EO has been in existence, but it's kind of been on the sidelines, been in the shadows, so to say. And this has really brought it into the, you know, into focus. And that has been, you know, very clear from my side, for example, over the past three weeks, once the EO had been, you know, been published and people had time to work through it, I've been getting a lot of people phoning, wanting to speak about DSM, wanting to better understand what's going on, wanting to see what the prospects are, wanting to understand, you know, what is the real story? Because everything that they've seen prior to this has been predominantly dominated by the anti-contingent who have been out trying to get moratorium in place. And what this has done has brought this sort of mainstream media and the mainstream interest into DSM. And that for me is a big, big step in the right direction. And it's also a great opportunity to create visibility, because the issue we've had has been a lack of visibility, a lack of understanding and a lack of context. And the EO certainly does address that. So I think it's valuable in that perspective. Catalyst is brought to you by ANSA. ANSA offers a one-of-a-kind data and analytics platform and advisory services to support better project development and procurement decisions. For energy storage developers, ANSA's platform provides crucial information that you never had easy access to before. Now at your fingertips is real-time pricing for a long list of system configurations to suit any project. ANSA provides a 360-degree view of the market with lifecycle cost analytics and commercial technical and risk data. With ANSA, developers can easily determine which products to use in their designs, finance models and RFPs. Learn more about how ANSA helps save time and maximize profit at go.anzerannuables.com slash latitude. Catalyst is brought to you by EnergyHub. EnergyHub helps utilities build next-generation virtual power plants that unlock reliable flexibility at every level of the grid. The EnergyHub platform takes the guesswork at a balancing energy supply and demand. It uses machine learning to control customer-owned distributed energy resources, like EVs, home batteries and smart thermostats to precisely shape load profiles for grid flexibility and reliability. As the industry leader, EnergyHub helps more than 80 utilities manage 1.6 million devices. That's more than any other edge derms on the market. Click the link in the show notes to learn more or go to energyhub.com. Okay, so before we move on from the US to talking about what's going on in the rest of the world, apart from sort of a less than ideal regulatory environment, are there other things that are going to be bottlenecks in the evolution of deep-sea mining within the United States? I mean, are we going to see significant exploration activity during the Trump administration before new administration takes hold and could make a bunch of changes if they so desired? Well, I think the key bottleneck with the US exclusive economic zone is the manner in which the US approaches mineral resource development. They've modeled the deep-sea mining of minerals and minerals in the ocean on the oil and gas model where the exploration work and a lot of the geophysical work that is that underpins this is done by the US government. And then based on that interpretation, they determine areas of interest that they put out on public lease for companies to bid and tender on. Now, the issue is with the deep-sea mineral space, is that means the likes of Boem and Noah have to go and do all of this work throughout this massive body of water. And they need to determine where exactly these mineral deposits are. Pull all the information together that would make it attractive for a company like us to bid on a lease. And the issue that you have is this is going to take multiple years of just exploration, sending ships out there and covering tens of thousands of square kilometers of the ocean. And I think this is going to be the problem. Noah's boats are already booked out for the next two to three years, possibly even the next four years. So before you can repurpose those vessels to specifically go and address this task, you have these jobs that they need to do, or you have to go and sacrifice those jobs and refocus them on this. And I think neither one of those is a great idea. What I would suggest is that the US take a leaf out of what everybody else is doing, where what they do is they put the onus on the person wanting to develop the resource. So if I use the example of the Cook Islands, for example, the government there has said to exploration companies, we will give you an exploration license that will give you exclusivity over that area for you to do your exploration. If you find resources within that area, you then have first right of refusal to apply for a mining license over it. So now I have done a couple of things. One is I've put the onus on companies that specialize in finding minerals to go and do the research and the exploration work in order to find them. And in return for that, what they are going to get is the right of first refusal to commercialize that. So the money that they invest, they get paid back through the project becoming commercial. And the benefit of that is you have people that specialize in this driving the process of doing it. So I think there's an interesting challenge that the US faces at the moment. If they want to follow through and deliver on the EO, I think there is a need for some significant changes that need to be done with regards to how they doing it at the moment. And if that is too big of a challenge, just change the contracting model. Don't rely on NOAA and BOEM to do it. In addition to that, look at some way of privatizing that exploration and giving people that specialize in it to help those agencies get to the point where commercialization of the resource in US territorial waters becomes a reality. Okay, you mentioned the Cook Islands. So moving on from the US, my sense is that the Cook Islands is furthest along here. Is that in terms of general exploration and moving toward actual deep sea mining? Do you agree with that, as anywhere else that you would put on the same levels of the Cook Islands? No, I think that would be a reasonably accurate statement. I think the country that is coming up close second to that would be Japan. Japan last year announced a fairly significant nodule field in their territorial waters and they are now moving forward with that development and that program under the guidance of the University of Tokyo. I think the Cook Islands are ahead of Japan in the fact that the Cook Islands have the regulatory frameworks in place to go from prospecting exploration and exploitation with a great environmental requirement and plan in place to make sure that there's no significant harm as a result of that. The Japanese still need to place some catch up there. So I would say between Japanese territorial waters Cook Islands, they certainly are as far as polymetallic nodules are concerned, certainly leading the way as far as deep sea minerals are concerned. Okay, so what is the latest in the Cook Islands? Who has got licenses to do what? How far along are they just orient me in terms of given the Cook Islands as the leader? Where are we? Yeah, so the Cook Islands back in 2022 awarded three exploration licenses to three different companies. So the first company is a company called Mahana Minerals, which is owned and operated by a US-based company called Ocean Minerals. You have CIC is the second license holder and then the third license holder is a joint venture between a Belgian company and the Cook Islands Investment Corporation, which is a government company that is focused on developing businesses within the Cook Islands. So those three companies have been awarded exploration licenses. Those licenses are five years in duration and the companies are currently in year four. And the intention and the plan of these organizations and Mahana Minerals is the company that I work for. The intention is in the next two years or so to apply for our mining licenses. So we are currently all embarked on the environmental data campaigns, collecting all the information so we can make the case for minimal environmental impact. But we also have our mining systems developed in our case and as well as the processing of the modules. So putting it a different way, we probably two to four years away from first production is where we are in the Cooks. You mentioned environmental data collection and trying to minimize environmental impact. Obviously that's been an area of contention historically, as you mentioned, with activists pushing for a moratorium and so on. From your perspective, is there a technical, is there a technological challenge in how do we actually extract resources while minimizing environmental footprint or is the technology known and proven already today? And it's just a matter of implementing it. The technology is known and proven and it has been proven and incidentally, the first time it was proven was back in the 1970s. So the tech for this has been around for multiple decades. As far as the environmental side is concerned, that's where the ISA comes into the picture. The work that the ISA has done over the past 20, 30, 40 years has been massive because it's really helped us focus on the specific areas where the impact would be and the technologies have obviously been modernized and updated to further reduce those impacts. So I think as a whole, the technology is there, how we apply it is well understood. What we are doing is establishing all the baseline data. To give you an idea, when you build a home, one of the things you have to do is look at the environmental impact of building your home. But the benefit you have is all the environmental data that exists. So you are very easily and quickly able to look at what the impacts of building your home would have. In the deep ocean where we are operating, we don't have that baseline data. And that is why we spend three, four years collecting that baseline data so that when we make the statements in our environmental impact statement, talking about what the impacts would look like, we are doing it from a data source and an unknown reference. And this is a process that will continue going on way beyond commencing of this operation. We have this plan called adaptive management, where we continually update the data we're collecting and how the systems operate and we keep refining and improving. The other technological question that I've heard that I think is kind of interesting is not about extraction so much as it is about refining. You mentioned you might be two to four years out and you and a couple others, two to four years out from production. So I understand that the challenge here is, okay, you get these polymetallic nodules, you extract them from the ocean floor, they contain a mixture of valuable minerals. They contain nickel and cobalt and copper and manganese. And our existing mineral refining, which we do from terrestrial mining, is not really set up for that because we don't have these polymetallic nodules in the same way on the ground or under the ground rather. And so what we have right now is a big refining industry set up to basically extract a single mineral, generally speaking. So does this mean that you are going to end up having to or having to find somebody set up some new refining infrastructure? Is that new technology? What does that look like downstream of extraction? So I think there are a couple of things to unpack. I think the first one is that we've recently started hearing a lot of noise about the processing technology doesn't exist. And that's an interesting shift in the arguments against why DSM should not go ahead. Because the reality is quite different. Yes, we have a polymetallic resource. So we have, as you mentioned, nickel, copper, cobalt, manganese, and in the case of the Cook Islands nodules, ray earths as well, which is another thing everybody's hot about. But the only part that we've had to crack and unlock is not the separation or the refining, because the separation or refining that exists with all these other mining industries is exactly the same technology that we're going to use to pull out those specific metals out of the nodules. So it's actually a benefit for us that all this knowledge and technology exists for selecting all those different metals. What is different for us is two things. The first one is the nodule is in the form of a golf ball size rock. And what we have to do is we have to get all those metals into, we refer to it as into solution. The best way to explain it is if you take table salt and you pour it into water and you dissolve it, it goes from sodium chloride, which is salt, and when you dissolve it, it becomes sodium ions and chloride ions in water. We do exactly the same thing, but instead of using water, we use acid. And what we do is we crush the nodules and we use acid and we dissolve all the metals. Now all the metals are floating around in this liquid and we apply all those existing technologies to strip them out. The only difference is we need to figure out in what sequence to pull them out to get the best results. You need basically a train of existing technologies. If it's a nickel mine or a nickel refining operation, you're just trying to pull out the nickel, you're going to do that, but then you also have to pull out the manganese and the copper and the cobalt. Now what that does is it starts creating some interesting possibilities for us. So nickel mines and copper mines are nickel cobalt or copper cobalt, so they bring up both those products. So one of the things we can do is create a nickel cobalt or a nickel copper cobalt hydroxide and we can send it to one of those existing facilities and they can pull them out. Or as you said, what we do is we build our own facility, but instead of having to invent a new process, we build an existing facility and we go to these different industries and we just go and take that building block that they've used and we put it into our plant. And this is all chemistry. So what you're talking about is big tanks with pumps and circulatory circuits and what you do is you either use electrolysis or you use chemistry to cause the metals to sink or to float and it's easy to separate them out or you just have them precipitate. In other words, you dry them out. So there's nothing unique, strange or different about what we're doing. It's just again like we did with the mining system, we're using different technologies that exist and we are just putting them together in a different sequence. And yes, we'll have to build a new processing facility, but that is no different to any mine. If you go to any mine on land, the processing facility is going to be built in order to meet the uniqueness of the chemistry of that particular mine. So every process plant that you go to is normally tied to some mine or some supply and there's uniqueness to it. It doesn't make us any different. If not a technical question, it is certainly a capital question. So maybe, I guess, final topic for us is to talk about capital formation here and not just for refining, but also for extraction. Or even on capex or an opx, I suppose, just on the extraction portion relative to a terrestrial mine, what should we be thinking about? Well, I think the first misperception that we hear often is that it can't make money because it's complicated and very expensive. And I think there are two parts that the complicated and expensive is all relative because at the end of the day, profitability of a mine is the difference between operating costs and revenue. And in our case, yes, we have got these ships that are going to see and they are operating in the ocean. And it is deemed to be expensive because we're working at great depths. However, we don't have all the big capital costs of infrastructure, power lines, roads, rails, dams, et cetera, which means the cost of capital for us is going to be lower. We are going to spend less money building a ship to go mining there, what you will do, perhaps building a brand new infrastructure in some outback area. So that's one aspect of it. The other thing to consider is that we are bringing up one ton of material. And in that one ton of material, we are producing the same amount of metal as you would need to have anywhere between three and five land-based mines. So for them to get the same amount of metal that we're getting because of our high grade and the fact that they multi-metal, you could end up moving anywhere between four and eight times the tonnage of raw rock to get the same metal. So those are the aspects that people don't understand because they haven't looked into the specifics. So when it comes to economics, we're moving less tonnage, we're getting more metal. The revenue we get in per ton is much higher, even though our up-ex cost per ton may be higher than dump trucks running with front-end loaders. But the revenue is certainly there that's offsetting that. It's like an up-ex cap-ex trade-off and you get a higher value product per unit volume or per unit weight. Absolutely. Yeah. At the end of the day, there are two things you need to look at. You need to look at what is the return on your investment. So for in our case, the mining system cap-ex is around $500 million. The processing plant, probably around $2 billion. But what for that investment do you get in return for your project? So our project is in anywhere between three and four billion dollar project that's going to yield in the region of $500 million of free cash flow per year. Put that in front of any land-based miner and they'll be falling over you to fund that project with IRRs in the 30s, 40%. This project, when you look at the economics and what it yields is a no-brainer. What we just have is the stigma around underwater in the ocean and a lot of the misinformation that has been put around it. I would really love to get into a situation where people just park their motions and look at it purely on merit from an environmental impact perspective, from a cost perspective, from just an overall impact of this generally. And just look at what we are going to get from it. I think they'll be pleasantly surprised. We talk about that free cash flow number. There's obviously an assumption embedded in there as to the price you can get for the minerals that you're extracting. I think one of the things that's interesting that here is that because you're polymetallic, rather than being subject to a single volatile commodity, you've at least got multiple. You could imagine prices for manganese spiking and nickel crashing at the same time and you end up in a wash or something like that. It's beneficial in that context. But obviously, particularly with nickel, we've seen prices low recently relative to history. How do you think about the volatility of those commodities? Obviously copper probably being the least volatile, but also probably a small portion of the value stack I would expect for a given polymetallic nodule. What matters, which minerals matter the most and how do you think about price volatility? One of the things we do for our investors is obviously a sensitivity analysis. One of the interesting things we are able to show is that with the recent crash of the cobalt price and nickel for all sorts of reasons, and that's the topic for a whole different discussion. But particularly those two metals with the depression on their prices, our project remains profitable. The reason it's profitable because of the manganese is by far the biggest component to what we're doing. The manganese market is so massive that it has a certain amount of robustness just due to its sheer volume and size. The other thing we hear from people is, are we going to come into production and we're going to have a negative impact on the market because of the volumes we bring to the market? That's not going to happen with the manganese market either. What we have is manganese is a great stabilizer and it allows us to be able to ride through the fluctuations we see in the nickel and cobalt prices. But at the recent low prices, the project has remained profitable. At the prices we're projecting at the time that we go into production, obviously it makes it really interesting as to the kind of returns that this project can yield. Thank you so much for the time. This is super interesting. I'll catch you in two to four years when you're pulling up commercial volumes. Look forward to it. Thanks very much. On the smit is the president and CEO of Ocean Minerals, one of the companies that is working on an exploration license in the Cook Islands. This shows a production of latitude media. You can head over to latitudemedia.com for links to today's topics. Latitude is supported by Prelude Ventures, Prelude Bex Visionaries accelerating climate innovation that will reshape the global economy for the betterment of people and planet. Learn more at PreludeVentures.com. This episode is produced by Daniel Waldorf. Mixing and theme song by Sean Markwan, Stephen Lacey is our executive editor. I'm Shale Khan and this is Catalyst.",
    "release_date": "2025-05-22",
    "duration_ms": 2224000,
    "url": "https://chrt.fm/track/G78F99/traffic.megaphone.fm/PSMI3479416220.mp3?updated=1747884584",
    "source": "Catalyst with Shayle Kann",
    "timestamp": "2025-06-15T02:08:37.737145"
  },
  {
    "title": "A former race car engineer on battery safety and supply chains [partner content]",
    "description": "From his days as an IndyCar race engineer to his current role as chief product officer for a leading storage integrator, Tristan Doherty has always worked at the intersection of high performance and risk management.\u00a0\n\nToday, he's applying that expertise at LG Energy Solution Vertech to build more resilient, domestically manufactured energy storage systems for America's evolving grid.\n\nLG Energy Solution Vertech is the US energy storage division of LG Energy Solution, which has committed $1.4 billion to manufacture batteries in the U.S., creating a hub capable of producing 16.5 gigawatt-hours of energy storage cells annually. This investment is part of the company's long-term strategy to diversify supply chains.\n\n\"We're on schedule for early next year to be a hundred percent non-Chinese in terms of all of the components and sub-components going into those ESS cells,\u201d says Doherty.\n\nThis manufacturing strategy is critical in a moment of trade uncertainty. While LG Energy Solution's substantial resources allow it to weather these challenges, smaller players in the supply chain face greater difficulties. \"We're seeing projects that are being paused, that are being delayed. We're seeing suppliers that are rethinking their strategy...the goalposts are continually shifting.\"\n\nBeyond manufacturing, LG Energy Solution has transformed its approach to system integration. Rather than simply connecting batteries to the grid, the company now designs comprehensive power solutions with grid needs as the starting point. Doherty describes this as \"flipping the script\" from an inside-out to an outside-in approach.\n\n\"The direction of design decisions and the direction of design intent has kind of flipped 180 degrees,\" he explains. \"It's creating much more effective and much more powerful designs.\"\n\nThis evolution in design philosophy extends to safety considerations as well. Following incidents like the Moss Landing fire, the industry has increasingly shifted toward containerized solutions that compartmentalize risk. According to Doherty, this approach, combined with other innovations, has contributed to a 97% reduction in energy storage system failure rates.\n\nAs unprecedented demand growth from data centers, electrification, and manufacturing transforms the grid landscape, Doherty sees energy storage playing a central role.\u00a0\n\n\"We've made immense strides and we've figured out a whole lot of really interesting and fascinating ways of using batteries. But I think there's a whole bunch more to come.\"\n\nThis episode was produced in partnership with LG Energy Solution Vertech. LG Energy Solution Vertech is the U.S. energy storage division of LG Energy Solution, here to be your lifetime energy storage partner. Learn more about the company's approach to safety, performance, and its commitment to the U.S. market.",
    "summary": "Tristan Doherty, a former race engineer turned chief product officer at LG Energy Solution Vertec, shares his journey from designing race cars to managing large-scale storage projects. He discusses the challenges and high-stakes nature of car racing, emphasizing the importance of real-time decision-making. The podcast delves into the recent fire incident at a lithium battery storage facility, highlighting the industry's focus on safety improvements and evolving design approaches. Tristan also explores LG's investments in US manufacturing and the impact of trade environment on project timelines. The conversation touches on system integration strategies and the advantages of vertical integration in driving effective and powerful designs.",
    "transcript": " This is a branded podcast from Latitude Studios. In the late 1990s, in the middle of the dot-com boom, Tristan Doherty thought he wanted to be a computer engineer. I got about halfway through my undergrad and I decided I didn't want to make little black boxes with blinky lights on them. I thought that was probably not very exciting. So I moved into mechanical engineering and I wanted to make robotics. I wanted to do stuff where I took control systems and impacted the real physical world. Tristan pursued projects that were far more interesting than boxes with blinky lights. He was on a university team that designed a formula-style race car. He designed interactive art that integrated technology. And at the end of school, he faced a question that lots of people grapple with. And I sort of had to make a decision at the end of that and I said, well, what's my true calling? Where am I being pulled? And at that point, I was being pulled back into car racing. Tristan went all in on racing. He started as a data acquisition engineer who analyzed tens of thousands of data points coming from a race. And he eventually became a race engineer for an IndyCar team who called the shots on the setup of the car. And ultimately, it's me on the radio saying pit pit pit and a lot of stress, a lot of pressure, but very rewarding. Car racing is a very high-stakes sport. It requires a team of engineers like Tristan to analyze data and make real-time decisions about how to operate the car. And as he told Stephen Lacey, once small mistake can be catastrophic. So it was really sort of a fascinating culmination of a lot of different areas that came together. In racing, you have this huge, obviously, technology piece of it. You have a big sports piece of it. You have a logistics piece where you have to make it to race day. And layered on top of that is the sort of psychology aspect of dealing with a driver and dealing with the teams. Were there any harrowing moments? What kind of problems were you having to overcome? Oh, there's a lot of problems in racing. There's a lot of chaos. I remember vividly once in Australia, we were doing the morning warm-up on Sunday morning. It was sort of a 9 AM warm-up or something for an 11 AM race. And these are usually really low stress. You just go out, you do a couple laps, make sure everything's okay. And we come back from the warm-up and the engine had failed and the engine needed to be replaced. And it was an impressive orchestra of chaos that brought the entire team together, everyone from the team owner down to the new mechanic who just joined a couple of weeks before that was just madly trying to get this engine fixed. And everyone is just sort of grabbing parts of what's needed here and there and just trying to really, you know, single-mindedly that one mission that the entire team was 100% focused on. It's a little clich\u00e9 maybe to bring that back to sort of climate and back to the energy transition. But I think that a lot of people in the industry have that similar sort of really sort of single-minded of what we had ahead of us and what we really need to accomplish. Today, Tristan is the chief product officer at LG Energy Solution Vertec, the vertically integrated US storage arm of LG Energy Solution. The company executes large-scale storage projects from cell manufacturing through system integration, O&M and warranties. We have to really deeply understand the technology and we have to understand the business. And hopefully when we solve everyone's problems, we find success. Tristan, who's no stranger to things going wrong from his racing days, is also focused on improving the safety of battery storage plants. Now let's get to developing news out of Monterey County, a fire burning at one of the world's largest lithium battery storage facilities. And it continues to burn more than 24 hours after it started. Earlier this year, the Moss Landing Battery Plant operated by Visitor Energy caught on fire and golfing the LG batteries inside the building. LG Energy Solutions provided the racks and batteries for this project, while other providers worked on the balance of systems. In the wake of the fire, Stephen Lacey sat down with Tristan to explore what has changed in the industry in the months afterward. It certainly was a huge wake-up call for the industry, a very pivotal moment for battery safety, but one that I think is going to drive us forward and really drive some positive changes that I'm looking forward to in the future. In this interview, Stephen and Tristan Outline Design changes why vertical integration is so critical for improving safety and performance and explore the future of US supply chains. So it seems appropriate since we have a former race engineer with us who has dealt with many challenges to start this conversation off by talking about safety. The Moss Landing Battery Fire in California that recently happened was a pretty pivotal moment for energy storage. I wonder if you can talk us through what happened and what we learned from that incident and how is it shaping the industry's approach to safety? I think as is always the case with these huge fires, there's some things we know. There's a lot we don't know yet and there's probably plenty that we may never know. Fundamentally though, and I think we don't yet know what the root cause is. We're working really, really closely with the site owner and all the local authorities to try and figure it out. What we do know is that mid-afternoon, January 16th, one of those modules went into Thermal Runaway. What we don't know yet is we don't have an official sort of answer on is for some reason that water system didn't work correctly. And that thermal runaway spread from one module to the next and eventually to the entire section of that building, ultimately destroying it. And so just a little bit of background about that site because it was an important site, I think, in the history of energy storage and energy storage deployments. It was the largest site by a long shot for many years. But it was a retrofitted gas and oil power plant that was originally built in the 50s. And in 2013, California passed a law that was sort of requiring a big build out of energy storage and Vistra, the project owner, answered that call in 2018 announcing that they were going to build this Moss Landing project. What they did was they essentially pulled all the equipment out of a massive turbine hole and they replaced it all with battery racks. The incident earlier this year was in that first phase of the Moss Landing complex. There's a couple other battery projects on that complex, but they weren't involved in this particular incident. I think that it's really worth noting that there was a certain era in the energy storage industry where anything over a certain size, any project over a certain size, and people listening to this may laugh when they say that certain size maybe was 20 or 30 megawatt hours, which seems teeny, tiny compared to today's standards. But anything that was of any meaningful size would typically go into a building. And that was just sort of the design practice of the time. Things have moved on quite a bit since then, but that was the case. And so these systems, they were racks essentially sitting in a building. They had a water-based fire safety system that was essentially when a thermal runaway was detected, it would spray water on the module to reduce the heat in that module and to make sure that that thermal runaway didn't propagate to the modules around it. And that's sort of the layout of this site. I think one thing that's really worth noting is that these huge projects, that there's a lot of different players on site. This was also a time in the industry when LG wasn't vertically integrated as it is today. And then there was sort of layers and layers and layers of other players at this project site. They all had to come together and everything had to work together to defer it all to function. What I'm really thankful for and I think everyone is really thankful for is that all the first responders did an amazing job and nobody was hurt. Thankfully, all the environmental measurements that came back, all the EPA's been doing extensive testing all around the site. All those measurements have come back within sort of safe limits. And I hope that in the next months, we're going to have a nice extensive report that will help the entire industry learn from this event. And are you seeing a shift to more containerized battery storage solutions compared to like a building-based installation like Moss Landing? How is that evolving and how does that impact safety? So definitely there has been a huge shift to containerized systems instead of building based systems. You see almost no building based systems built now anymore. Everything is essentially containerized. There are a lot of different reasons for that. It's one big one, but I think safety is another aspect that's an important piece to talk about. Fundamentally, I find the easiest way to think about why containers help on the safety front is that you're just splitting the problem into smaller pieces. A container has a limited amount of energy in it. It has its own fire safety systems in it. And it has walls and potentially even air gaps around it. So when one container or when one module in a container goes into a failure, goes into a thermal runaway. Ideally, that module is dealt with by the fire safety system. Maybe hopefully that module just turns into a non-event. That module has failed. You pull it out, you replace it with a new one. What you think about in terms of safety, you think about worst-case scenarios. And now the worst-case scenario is simply that you lose a container. Maybe the next container over gets a couple of scorch marks on it, but typically right now the worst-case scenario is you lose one container, which is several orders of magnitude less than what we saw at Moss Landing. And so fundamentally, what's your problem? Make it a smaller problem. And then when that problem happens, it's much more manageable. So looking ahead, are there other safety innovations or design approaches that you're also excited about that can improve safety? That's a great question. I see there's a lot of innovation happening right now at a lot of different levels. There's plenty of cell-level innovation that's happening. There's a lot of chemistry work and a lot of cell safety work that's happening. But I also see a huge amount of effort and a lot of progress being made at the system level. From a safety innovation perspective and from a design approach perspective, I really think that it's a multi-tiered approach. We're continuing to see a lot of system-level safety improvements that are happening along with the cell-level improvements. I see a huge play in terms of software. There's a big component to software and all the algorithms and AI and machine learning that are really being able to identify and catch failures before they turn into bigger failures. There's a lot of advancements here in terms of how much data is being collected and how you relate that to the things you know about the cells. And honestly, that's one of the big advantages that as a vertically integrated play that we have because we have this entire lifecycle of data that goes along with that we sell. But over top of it all, I think there's a big piece in terms of quality. And I talk about quality not only at the cell level and the manufacturing level but also at the system level and how these projects are coming together. And I think that there are a lot of sort of top tier integrators that have done a really great job of quality at the project level. But there's also this layer of codes and standards which I think is something that you think at the industry level that's going to force and require every single project that gets deployed to really meet that high bar of safety and system effectiveness. I want to sort of go back though a little bit and take note of how far we've come. And I think there's an eppery report out there that I think a lot of people in the industry have probably read and seen. But if you look at the number of failures and the failure rate from 2018 to 2023, it was just a five year span that it dropped by 97%. And I think that's something that's really incredible and something to be really proud of. Obviously we still have a long ways to go and there's still a lot of work ahead of us. But the knowledge that we made that much progress in that short a time period I think gives me a lot of confidence that these advancements are coming and that we'll get where we need to get. Let's turn our attention to manufacturing now. I know LGES has made some pretty big investments in US manufacturing. Can you talk about what those investments entail and what's the strategic approach to the American market? We've made a lot of very big investments. Right now we've been working heavily on localizing our production into the US. We've been doing that for a long time. Just for a little context, we started construction on our first factory in the US and Holland, Michigan. That was back in 2010. So that's almost 15 years ago that we've been working on this. We had cells coming off that line in 2012. That was back in, that was for the EV market. But we've continued to build from there. Right now we've got seven battery plants in the US that are either producing or in construction. We've got it also in advanced cathode facility. The one in there that I care the most about being on the energy storage side is our Holland Michigan. It's the second Holland Michigan plant that's producing 16.5 gigawatt hours a year of energy storage dedicated cells. That's our side of the investment. For many years we've had a strong strategy of diversifying away from China. We sort of have a two-step strategy to localize into the states. Step one is to find a supplier that is outside of China so that we have a more of a global supply chain. And then step two is to bring that supply chain into the US. That takes a long time. I think that's something that is sometimes lost. It seems really easy. Just flip a switch and we'll just build this stuff in the States. It takes years to build local supply chains, to qualify local supply chains, to get the right people and the right skill sets locally to be able to build what are ultimately really high-tech products. But I think so far we've been quite successful and we're in a good spot. Right now coming off of the Holland Michigan line we're on schedule for early next year to be 100% non-Chinese in terms of all of the components and sub-components that are going into those ESS cells. So it's a huge testament to the work and it's a lot of work that's gone into it by both the US and the Korean teams to make all that happen. So this has been a long-term strategy to invest in the US and diversify your supply chains. Of course this became a lot more urgent coming out of the supply chain disruptions from COVID and now we have these new challenges related to tariffs. How is the current trade environment impacting project timelines and your investment decisions? Taking a lot of analysis and reanalysis and re-reanalysis every time something changes. I think there's a lot of uncertainty right now in the environment and we've been lucky that we can be very flexible but it's also been a huge strain on I think us and everyone in the organization and everyone in the supply chain and everyone in the industry. We have to remember that these are enormous investments. LG's got sort of 25 billion investing in the US supply chains, 1.4 billion on that ESS factory. That's not something you just turn on and off at a moment's notice. You have to have a little bit of certainty. You have to know that it's going to make sense from a business perspective to be able to put down that kind of money. And I were lucky that we're a large multinational company with a balance sheet that can weather some of this uncertainty but it's not unlimited. What I do worry is I worry that there's a lot of other players in the supply chain, in the broader supply chain that don't have those kinds of balance sheets and maybe can't afford to have that kind of patience. We're seeing projects that are being paused, that are being delayed. We're seeing suppliers that are rethinking their strategy and what makes sense and what doesn't make sense. It's the goalposts are continually shifting and when that happens you don't really know what to do and so you're sort of paralyzed. What I really fundamentally worry about I think for the industry is not that we're not going to keep moving forward. I really do fundamentally believe that the economics are there for this industry and I think that the ultimate goal is something that we will achieve. It's just a matter of when and how fast. And this uncertainty I think all it does is it just slows that down. If you don't give people a clear signal they're not going to know what to do and they're not going to react in the most effective way possible and people are going to make, I call it a millimeter of progress in a million directions, which isn't an effective way when you're wanting to get single-minded leap to an end goal. I want to get your thoughts on integration strategies. So there has been a significant evolution in the size and type and integration strategies for storage from building batteries and connecting them to the grid to designing power plants that happen to use batteries. How has this change driving system integration and project development? I think that there's been a real strong shift in the mentality of how you integrate these plants and being a part of a company that has control over the supply chain from the cell all the way out to your transformer or even your interconnection allows us to think differently. We've kind of been able to flip the script on how exactly to do these projects. Originally, if you run the clock back into the early 2010s, a lot of people would say, hey, I have all these batteries. I've got maybe some EV batteries. What can I do with them? Well, let's put them together in a rack. Let's put those racks together in container. Let's put those containers together in a project. It was very, very inside out. Starting at the cell and then it was sort of multiplying and building and to create your project. Whereas I think the mentality has taken a strong shift and now we're thinking from the outside in. We're saying, what does a power plant look like? What value does it need to bring to the grid? What does it need to do to be really effective and to meet the business goals of the operator? What do the batteries need to do that are going to do that? You start at the power plant and then you move into your power block or your enclosure and then you move there into your module and you move from there into your cell. The direction of design decisions and the direction of design intent has kind of flipped 180 degrees, which is a fascinating change to see in the industry. But it's also one that I think is creating much more effective and much more powerful designs. What are the advantages of vertical integration? Well, the ability to do exactly what I just mentioned is when you're a system integrator and you're using a third-party cell, you're often kind of stuck with what your cell suppliers have. You've got to look through your catalog, figure out what's out there, how you put it all together to meet the need. When you're fully vertically integrated and you are understanding what the customer is truly needing and you can take that information and pick up the phone and talk to the designers who are actually designing the modules and the cells and describe to them what challenges you're facing. They understand that they can make their designs work much, much better with the overall plant. I think that's really a strong key. I see another big strength of vertical integration in just understanding and being able to control the supply chain and being able to manage the supply chain. One of our advantages and one of our superpowers as a battery company and being the largest non-Chinese battery company out there is that we have not only ESS production, but we also have EV production. This was one of the plays when we decided to shift our original plans of building the ESS production facility in Arizona and shift that to Holland, Michigan. It was so that we could build cells, more cells and build them sooner. That was only because we had the experience in the EV plants and we had this EV plant and we had these facilities that we saw market shifting. We saw that the EV market wasn't growing quite as fast as the ESS market was, that our forecasts were not quite right, but we could readjust. We had that ability to be flexible and we had that ability to readjust. Then instead of taking three or four years to build a complete green-fueled battery factory in Arizona, we could take six to 12 months, take an existing shell, an existing building that had all the permitting done and had all the infrastructure and all the utilities, take all that equipment that it was originally destined for Arizona, send it to Michigan and we were suddenly up and running almost a year earlier with ultimately a higher level of production per year. That vertical integration, that ability to maneuver things around and change and adjust to the market environments and the conditions really gives you the ability to be more flexible and to be more adaptable and what is ultimately a really variable environment right now. The players that have that adaptability and have that power are in a good spot right now. Tell me about how the software is evolving. As the use cases for storage on the grid diversify, what is happening in the software side as part of that stack? How are you approaching software development? What's changing that's most interesting? Yeah, software is an interesting piece. I think there's a lot of really interesting technology that's happening on the software side. There's a lot of AI machine learning that we mentioned earlier in terms of the safety aspect. There's a lot of operational efficiency and keeping really high availability of your systems. We're also working a lot with how to operate energy storage more effectively on the grid. What's the optimal dispatch? What's the way to play in the power markets and really be effective there? I think the other side of software and it flows into availability and safety is the cybersecurity piece and the domestic supply chain piece. I see software as a really key component of our supply chain. The fact that we build all of our software either in the US or in Korea, the fact that we have 100% visibility over every piece of every single controller in our enclosure, I think puts us in a stronger stance, I think, from a safety and cybersecurity perspective. I'm happy to see that we've brought all that in, that that's actually one of the really strong components that we bring to market. It just fundamentally I think makes for a better product. It's more secure, it's more stable and ultimately it's going to bring better value to the customer. It's impossible to have this conversation without talking about the demand backdrop now that is making storage even more valuable. Of course, around the world, but particularly here in the US we're seeing this surge in demand particularly due to data centers. It's a wide variety of things like electrification, factory development and data centers. I'm curious about how you see this shaping the market for storage. Is it changing the need for storage, the applications for storage? How do you see this demand backdrop influencing deployment? Well, there's a lot. It's a very foundational shift in the energy markets and the energy space. Everyone I think most people know has been talked about quite a bit in the last sort of six, 12 months, but our electricity demand as a country has been fairly stable and fairly flat for the last couple of decades. Only now we're starting to really pick up. It's a good thing because we're picking up economic activity. We're picking up these data centers. We're picking up manufacturing, but it's also a big challenge that we have ahead of us. Now, what's that crystal ball and how do you tell what that future holds? Is it 30 gigawatts of extra data center demand? Is it 60 gigawatts of extra data center demand? Is it even more than that? What's the overall demand growth? Is it going to be 50, 100, 200 gigawatts total? The sort of band of uncertainty is quite wide in terms of what the future holds and what that demand growth is actually going to be. I think what the trillion dollar question really is is how you go about serving that demand. Whatever it is, it's going to be big. It's going to be very big. But how do you get to serving that demand? There's a lot of different options on the table. I think every energy option out there is being looked at and is needed in solving this problem, but the timelines are quite varying. Nukes are probably five or 10 or more years out. New gas generation, you can't get a new gas generator for probably four or six years at the very shortest. The most immediate and economical solution is really those renewables and batteries. I think from a pure data center play, you brought that up. What are the specifics in terms of how we address the data center needs? There's a lot of variability there. I think that goes back to speaking to the uncertainty in exactly how we're going to bring all this online. There's everything from completely off-grid microgrids that are powering data centers until they can get grid connections to working really closely with utilities to bring extra generation on board. I think there's a lot of questions there, but there's a lot of smart people in the industry that are working really hard on those. I've got a lot of confidence and a lot of faith. Do you think we'll see a lot of batteries hosted at data centers? Yes, I think we'll see a lot of batteries at data centers. I think we'll see a lot of batteries on the grid next to data centers. I think we'll see a lot of batteries that are on the grid far away from data centers. I think we're just going to see a lot of batteries everywhere on the grid. We've made immense strides and we've figured out a whole lot of really interesting and really fascinating ways of using batteries, but I think that there's a whole bunch more that are to come. I'm really excited for what's going to come. We've covered innovations in safety, system design, integration, strategy, supply chain development. What other technical innovations and batteries are you most excited about right now? I think obviously there's a lot of technology advancement. I think there's some great battery chemistry plays coming out. I think that as the markets shift to these longer and longer duration, some of these longer duration battery chemistry plays could be really interesting if they hit the right timing. I do think that the advancements that I'm most excited about are really how to get that deployment to be smooth, how to get that deployment to be effective, how to keep these systems really up 99% of the time, 99.5% of the time, just keeping that massive, really, really stable uptime and get the reliability that you need to support the grid. Fundamentally though, I do think that we have a great technology in LFP and that we're starting to get really good at deploying these huge sites quickly and effectively and that there's just a lot more value that we're going to get out of them as we learn to manage fleets that are at the tens or hundreds of gigawatt hour scale or even thousands of gigawatt hour scale. That's where a lot of the advancement is going to come. It's the scaling question and the scaling problem that we have ahead of us. Do you still get the same thrills working on energy storage as you did working on Indy cars? I'll be honest, every time you turn on a one gigawatt hour site, there's a little bit of a thrill. There's a little bit of excitement to see that happening. It is still fun for sure. Tristan Doherty, thank you so much. I enjoyed this conversation. Likewise, thank you for having me. This episode was produced in partnership with LG Energy Solution Vertec. LG Energy Solution Vertec is the US Energy Storage Division of LG Energy Solution, here to be your lifetime energy storage partner. For more on the company's approach to safety, performance and its commitment to the US market, follow the link in the show notes.",
    "release_date": "2025-05-20",
    "duration_ms": 1597000,
    "url": "https://chrt.fm/track/G78F99/traffic.megaphone.fm/PSMI1882358341.mp3?updated=1747684845",
    "source": "Catalyst with Shayle Kann",
    "timestamp": "2025-06-15T02:11:50.611709"
  }
]